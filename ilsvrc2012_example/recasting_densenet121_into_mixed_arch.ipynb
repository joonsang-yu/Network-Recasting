{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "from model_generator import ModelGenerator\n",
    "from net import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi gpu mode\n",
    "from DataParallel_KD import DataParallel_KD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Hyper parameters #############################\n",
    "\n",
    "num_workers = 32\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "lr_recasting = 0.0005\n",
    "lr_fine_tune = 0.0001\n",
    "\n",
    "num_epoch_recasting = 10\n",
    "num_epoch_fine_tune = 20\n",
    "\n",
    "scheduler_step_size = 7\n",
    "\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen = ModelGenerator(dropout = False, batchnorm = True)\n",
    "model_gen.ImagenetDensenetConfig(num_layers = 121)\n",
    "\n",
    "# Recasting block\n",
    "# 0: conv layer, 1, 3, 5, 7: Dense block, 2, 4, 6: Transition block\n",
    "recasting_block_indices = [1, 3]\n",
    "target_block_type = 'ResidualBlock'\n",
    "\n",
    "# Compression rate\n",
    "# the number of filters decreased to [compression_rate]\n",
    "\n",
    "compression_ratio = 1\n",
    "\n",
    "## file path\n",
    "pretrained_model = './imagenet_densenet121_pretrained.pth'\n",
    "compressed_model = './imagenet_densenet121_to_mixed_arch.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_classes = '1000'\n",
      "num_valid_classes = '1000'\n"
     ]
    }
   ],
   "source": [
    "## DGX-1\n",
    "traindir = os.path.join('/home/data/ILSVRC2012/images', 'train')\n",
    "valdir = os.path.join('/home/data/ILSVRC2012/images', 'val')\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=traindir, transform=transform_train)\n",
    "testset = torchvision.datasets.ImageFolder(root=valdir, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "num_train_classes = len([name for name in os.listdir(traindir)])\n",
    "num_valid_classes = len([name for name in os.listdir(valdir)])\n",
    "\n",
    "print(\"num_train_classes = '{}'\".format(num_train_classes))\n",
    "print(\"num_valid_classes = '{}'\".format(num_valid_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_gen.GetImagenetDensenet()\n",
    "teacher = Net(model)\n",
    "\n",
    "state = torch.load(pretrained_model)\n",
    "teacher.LoadFromStateDict(state)\n",
    "\n",
    "teacher.Gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Top1 Acc: 9.42 %, Top5 Acc: 19.08 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "correct_top5 = 0\n",
    "correct_tmp = 0\n",
    "\n",
    "total = 0\n",
    "\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    \n",
    "    \n",
    "    outputs = teacher(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "    \n",
    "    _, predicted_top5 = torch.topk(outputs.data, 5)\n",
    "    predicted_top5 = predicted_top5.t()\n",
    "    predicted_top5_mat = predicted_top5.eq(labels.cuda().view(1,-1).expand_as(predicted_top5))\n",
    "\n",
    "    del outputs\n",
    "    for k in (1,5):\n",
    "        correct_tmp = predicted_top5_mat[:k].view(-1).float().sum(0, keepdim=True)\n",
    "    \n",
    "    correct_top5 += correct_tmp[0]\n",
    "\n",
    "    print ('.', end=' ')\n",
    "\n",
    "print ('\\n')\n",
    "print('Top1 Acc: %4.2f %%, Top5 Acc: %4.2f %%' %(100 * correct / total, 100 * correct_top5 / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_gen.GetImagenetDensenet()\n",
    "student = Net(model)\n",
    "\n",
    "state = torch.load(pretrained_model)\n",
    "student.LoadFromStateDict(state)\n",
    "\n",
    "student.Gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Top1 Acc: 9.42 %, Top5 Acc: 19.08 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "correct_top5 = 0\n",
    "correct_tmp = 0\n",
    "\n",
    "total = 0\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "\n",
    "    outputs = student(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "    \n",
    "    _, predicted_top5 = torch.topk(outputs.data, 5)\n",
    "    predicted_top5 = predicted_top5.t()\n",
    "    predicted_top5_mat = predicted_top5.eq(labels.cuda().view(1,-1).expand_as(predicted_top5))\n",
    "\n",
    "    del outputs\n",
    "    for k in (1,5):\n",
    "        correct_tmp = predicted_top5_mat[:k].view(-1).float().sum(0, keepdim=True)\n",
    "    \n",
    "    correct_top5 += correct_tmp[0]\n",
    "\n",
    "    print ('.', end=' ')\n",
    "\n",
    "print ('\\n')\n",
    "print('Top1 Acc: %4.2f %%, Top5 Acc: %4.2f %%' %(100 * correct / total, 100 * correct_top5 / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential recasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block 1 recasting is done (DenseBlock -> ResidualBlock).\n",
      "Training start\n",
      "\n",
      "Top1 Acc: 69.81 %, Top5 Acc: 89.38 %\n",
      "\n",
      "\n",
      "\n",
      "Block 3 recasting is done (DenseBlock -> ResidualBlock).\n",
      "Training start\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define MSE loss\n",
    "MSE = nn.MSELoss()\n",
    "\n",
    "teacher.TestMode()\n",
    "\n",
    "for block_idx in recasting_block_indices:\n",
    "    \n",
    "    ################################################    Recasting process ######################################################\n",
    "    # current block recasting\n",
    "    \n",
    "    config = student.GetBlockConfig(block_idx)\n",
    "    \n",
    "    config[2] = round(config[2] * compression_ratio)    # apply compression ratio\n",
    "    \n",
    "    # Handling corner case: bottleneck block recasting\n",
    "    if len(config) == 5:                         \n",
    "        is_bottleneck = True\n",
    "        mid_feature = config[4]\n",
    "        # We reduce the output dimension of bottleneck block.\n",
    "        # output dimension of new block is the same with output dimension of 3x3 conv in bottleneck block\n",
    "        config[4] = round(mid_feature * compression_ratio)\n",
    "    else :\n",
    "        is_bottleneck = False\n",
    "        \n",
    "    new_block = model_gen.GenNewBlock([target_block_type, config])\n",
    "    source_block_type = config[0]\n",
    "    \n",
    "    student.Recasting(block_idx, new_block)\n",
    "    \n",
    "    \n",
    "    # next block recasting\n",
    "    \n",
    "    config = student.GetBlockConfig(block_idx + 1)\n",
    "    \n",
    "    config[1] = round(config[1] * compression_ratio)    # apply compression ratio\n",
    "    \n",
    "    # Handling corner case: bottleneck block recasting\n",
    "    if is_bottleneck == True:                         \n",
    "        # Change next input dim to output dim of target block\n",
    "        config[1] = round(mid_feature * compression_ratio)\n",
    "    \n",
    "    new_block = model_gen.GenNewBlock([config[0], config])\n",
    "    student.Recasting(block_idx + 1, new_block)\n",
    "    \n",
    "    ################################################    Recasting process end ##################################################\n",
    "    \n",
    "    \n",
    "    student.Gpu()\n",
    "    \n",
    "    params = student.GetCurrParams(block_idx)\n",
    "    \n",
    "    optimizer = optim.Adam(params, lr = lr_recasting)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size = scheduler_step_size)\n",
    "    \n",
    "    print('\\nBlock %d recasting is done (%s -> %s).' %(block_idx, source_block_type, target_block_type))\n",
    "    print('Training start\\n')\n",
    "    for epoch in range(num_epoch_recasting):  # loop over the dataset multiple times\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        scheduler.step()\n",
    "        \n",
    "        student.TrainMode()\n",
    "            \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            corrects = teacher(inputs, next_block= block_idx + 1)\n",
    "            targets = Variable(corrects.data.cpu().clone())\n",
    "            del corrects\n",
    "            \n",
    "            outputs = student(inputs, next_block = block_idx + 1)\n",
    "            \n",
    "            loss = MSE(outputs, targets.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del outputs\n",
    "            \n",
    "            running_loss = (running_loss * i + loss.cpu().data.numpy()) / (i+1)\n",
    "            \n",
    "        \n",
    "    correct = 0\n",
    "    correct_top5 = 0\n",
    "    correct_tmp = 0\n",
    "\n",
    "    total = 0\n",
    "\n",
    "    student.TestMode()\n",
    "\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "\n",
    "        outputs = student(Variable(images.cuda()))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "        _, predicted_top5 = torch.topk(outputs.data, 5)\n",
    "        predicted_top5 = predicted_top5.t()\n",
    "        predicted_top5_mat = predicted_top5.eq(labels.cuda().view(1,-1).expand_as(predicted_top5))\n",
    "\n",
    "        del outputs\n",
    "        for k in (1,5):\n",
    "            correct_tmp = predicted_top5_mat[:k].view(-1).float().sum(0, keepdim=True)\n",
    "\n",
    "        correct_top5 += correct_tmp[0]\n",
    "\n",
    "    print('Top1 Acc: %4.2f %%, Top5 Acc: %4.2f %%' %(100 * correct / total, 100 * correct_top5 / total))\n",
    "    print ('\\n')\n",
    "        \n",
    "\n",
    "print('Recasting is finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning (KD + Cross-entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# define loss functions\n",
    "MSE = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# pruning ratio for every layer    \n",
    "optimizer = optim.Adam(student.GetTotalParams(), lr = lr_fine_tune)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size = scheduler_step_size)\n",
    "teacher.TestMode()\n",
    "student.Gpu()\n",
    "\n",
    "print('Fine tuning start')\n",
    "\n",
    "for epoch in range(num_epoch_fine_tune):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    student.TrainMode()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        corrects = teacher(inputs)\n",
    "        targets = Variable(corrects.data.cpu().clone())\n",
    "        del corrects\n",
    "            \n",
    "        outputs = student(inputs)\n",
    "\n",
    "        loss_KD = MSE(outputs, targets.cuda())\n",
    "        loss_CE = criterion(outputs, labels)\n",
    "        \n",
    "        loss = loss_KD + loss_CE\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del outputs\n",
    "        \n",
    "        running_loss = (running_loss * i + loss.cpu().data.numpy()) / (i+1)\n",
    "        \n",
    "\n",
    "    \n",
    "    if epoch % 5 == 0 :\n",
    "        correct = 0\n",
    "        correct_top5 = 0\n",
    "        correct_tmp = 0\n",
    "\n",
    "        total = 0\n",
    "\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "\n",
    "            outputs = student(Variable(images.cuda()))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "            _, predicted_top5 = torch.topk(outputs.data, 5)\n",
    "            predicted_top5 = predicted_top5.t()\n",
    "            predicted_top5_mat = predicted_top5.eq(labels.cuda().view(1,-1).expand_as(predicted_top5))\n",
    "\n",
    "            for k in (1,5):\n",
    "                correct_tmp = predicted_top5_mat[:k].view(-1).float().sum(0, keepdim=True)\n",
    "\n",
    "            correct_top5 += correct_tmp[0]\n",
    "\n",
    "            del outputs\n",
    "            \n",
    "        print ('\\n')\n",
    "        print('Top1 Acc: %4.2f %%, Top5 Acc: %4.2f %%' %(100 * correct / total, 100 * correct_top5 / total))\n",
    "        \n",
    "    else :\n",
    "        print ('.', end=' ')\n",
    "\n",
    "    \n",
    "print('Fine tuning is finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
