{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "from model_generator import ModelGenerator\n",
    "from net import Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epoch  = 300\n",
    "\n",
    "lr = 0.1\n",
    "gamma = 0.2             # learning rate decay\n",
    "weight_decay = 0.0001\n",
    "\n",
    "## for SGD\n",
    "opt_momentum = 0.9\n",
    "opt_nesterov = True\n",
    "\n",
    "dropout_on = False\n",
    "batchnorm_on = True \n",
    "\n",
    "scheduler_step_size = [150, 225]\n",
    "\n",
    "pretrained_model       = './cifar10_densenet100_pretrained.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomCrop(32, 4),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define densenet 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen = ModelGenerator(dropout = dropout_on, batchnorm = batchnorm_on)\n",
    "\n",
    "model_gen.CifarDensenetConfig(k = 12, num_layers = 100, cifar = 10)\n",
    "model = model_gen.GetCifarDensenet()\n",
    "\n",
    "net = Net(model)\n",
    "\n",
    "net.Gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.GetTotalParams(), lr=lr, weight_decay=weight_decay, momentum=opt_momentum, nesterov=opt_nesterov )\n",
    "\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones = scheduler_step_size, gamma = gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (back-propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch end, loss: 1.389578, Test Acc: 60.13 %\n",
      "2 epoch end, loss: 0.867029, Test Acc: 66.03 %\n",
      "3 epoch end, loss: 0.684609, Test Acc: 73.19 %\n",
      "4 epoch end, loss: 0.582835, Test Acc: 79.06 %\n",
      "5 epoch end, loss: 0.529145, Test Acc: 78.93 %\n",
      "6 epoch end, loss: 0.487295, Test Acc: 81.49 %\n",
      "7 epoch end, loss: 0.456000, Test Acc: 82.60 %\n",
      "8 epoch end, loss: 0.434502, Test Acc: 82.15 %\n",
      "9 epoch end, loss: 0.416055, Test Acc: 84.02 %\n",
      "10 epoch end, loss: 0.395450, Test Acc: 83.91 %\n",
      "11 epoch end, loss: 0.387572, Test Acc: 85.10 %\n",
      "12 epoch end, loss: 0.370715, Test Acc: 84.26 %\n",
      "13 epoch end, loss: 0.365019, Test Acc: 85.99 %\n",
      "14 epoch end, loss: 0.354776, Test Acc: 85.48 %\n",
      "15 epoch end, loss: 0.346449, Test Acc: 82.81 %\n",
      "16 epoch end, loss: 0.340789, Test Acc: 83.80 %\n",
      "17 epoch end, loss: 0.334127, Test Acc: 79.47 %\n",
      "18 epoch end, loss: 0.327496, Test Acc: 84.46 %\n",
      "19 epoch end, loss: 0.320897, Test Acc: 84.96 %\n",
      "20 epoch end, loss: 0.313461, Test Acc: 83.26 %\n",
      "21 epoch end, loss: 0.308879, Test Acc: 84.60 %\n",
      "22 epoch end, loss: 0.312986, Test Acc: 87.46 %\n",
      "23 epoch end, loss: 0.304134, Test Acc: 84.65 %\n",
      "24 epoch end, loss: 0.299003, Test Acc: 84.58 %\n",
      "25 epoch end, loss: 0.296499, Test Acc: 85.16 %\n",
      "26 epoch end, loss: 0.294895, Test Acc: 83.77 %\n",
      "27 epoch end, loss: 0.293409, Test Acc: 86.93 %\n",
      "28 epoch end, loss: 0.287244, Test Acc: 85.92 %\n",
      "29 epoch end, loss: 0.277981, Test Acc: 84.67 %\n",
      "30 epoch end, loss: 0.279035, Test Acc: 87.39 %\n",
      "31 epoch end, loss: 0.275344, Test Acc: 86.36 %\n",
      "32 epoch end, loss: 0.271097, Test Acc: 87.08 %\n",
      "33 epoch end, loss: 0.270009, Test Acc: 87.29 %\n",
      "34 epoch end, loss: 0.269069, Test Acc: 88.05 %\n",
      "35 epoch end, loss: 0.263600, Test Acc: 87.52 %\n",
      "36 epoch end, loss: 0.256816, Test Acc: 86.09 %\n",
      "37 epoch end, loss: 0.257205, Test Acc: 85.79 %\n",
      "38 epoch end, loss: 0.256046, Test Acc: 87.14 %\n",
      "39 epoch end, loss: 0.255286, Test Acc: 87.96 %\n",
      "40 epoch end, loss: 0.250720, Test Acc: 85.71 %\n",
      "41 epoch end, loss: 0.247342, Test Acc: 87.07 %\n",
      "42 epoch end, loss: 0.250998, Test Acc: 87.96 %\n",
      "43 epoch end, loss: 0.246194, Test Acc: 87.12 %\n",
      "44 epoch end, loss: 0.241711, Test Acc: 87.26 %\n",
      "45 epoch end, loss: 0.242210, Test Acc: 87.58 %\n",
      "46 epoch end, loss: 0.235553, Test Acc: 87.72 %\n",
      "47 epoch end, loss: 0.235465, Test Acc: 88.34 %\n",
      "48 epoch end, loss: 0.235255, Test Acc: 87.97 %\n",
      "49 epoch end, loss: 0.228969, Test Acc: 87.20 %\n",
      "50 epoch end, loss: 0.232603, Test Acc: 88.54 %\n",
      "51 epoch end, loss: 0.229835, Test Acc: 87.60 %\n",
      "52 epoch end, loss: 0.228196, Test Acc: 87.90 %\n",
      "53 epoch end, loss: 0.225742, Test Acc: 89.40 %\n",
      "54 epoch end, loss: 0.225253, Test Acc: 89.15 %\n",
      "55 epoch end, loss: 0.225005, Test Acc: 87.74 %\n",
      "56 epoch end, loss: 0.225616, Test Acc: 85.46 %\n",
      "57 epoch end, loss: 0.223112, Test Acc: 88.38 %\n",
      "58 epoch end, loss: 0.226101, Test Acc: 84.52 %\n",
      "59 epoch end, loss: 0.221478, Test Acc: 88.90 %\n",
      "60 epoch end, loss: 0.219041, Test Acc: 88.94 %\n",
      "61 epoch end, loss: 0.213334, Test Acc: 89.14 %\n",
      "62 epoch end, loss: 0.218165, Test Acc: 90.43 %\n",
      "63 epoch end, loss: 0.216315, Test Acc: 89.02 %\n",
      "64 epoch end, loss: 0.214824, Test Acc: 87.70 %\n",
      "65 epoch end, loss: 0.215080, Test Acc: 85.88 %\n",
      "66 epoch end, loss: 0.213907, Test Acc: 88.08 %\n",
      "67 epoch end, loss: 0.212635, Test Acc: 88.85 %\n",
      "68 epoch end, loss: 0.212965, Test Acc: 88.38 %\n",
      "69 epoch end, loss: 0.212566, Test Acc: 86.82 %\n",
      "70 epoch end, loss: 0.206106, Test Acc: 88.67 %\n",
      "71 epoch end, loss: 0.215507, Test Acc: 87.76 %\n",
      "72 epoch end, loss: 0.209317, Test Acc: 88.40 %\n",
      "73 epoch end, loss: 0.206490, Test Acc: 89.93 %\n",
      "74 epoch end, loss: 0.208991, Test Acc: 88.72 %\n",
      "75 epoch end, loss: 0.207230, Test Acc: 90.02 %\n",
      "76 epoch end, loss: 0.208703, Test Acc: 89.14 %\n",
      "77 epoch end, loss: 0.202954, Test Acc: 89.31 %\n",
      "78 epoch end, loss: 0.204600, Test Acc: 85.48 %\n",
      "79 epoch end, loss: 0.208701, Test Acc: 89.74 %\n",
      "80 epoch end, loss: 0.201247, Test Acc: 89.43 %\n",
      "81 epoch end, loss: 0.200219, Test Acc: 89.60 %\n",
      "82 epoch end, loss: 0.200266, Test Acc: 88.96 %\n",
      "83 epoch end, loss: 0.200766, Test Acc: 89.95 %\n",
      "84 epoch end, loss: 0.200921, Test Acc: 88.71 %\n",
      "85 epoch end, loss: 0.200305, Test Acc: 88.08 %\n",
      "86 epoch end, loss: 0.203036, Test Acc: 89.50 %\n",
      "87 epoch end, loss: 0.202054, Test Acc: 89.25 %\n",
      "88 epoch end, loss: 0.201599, Test Acc: 90.30 %\n",
      "89 epoch end, loss: 0.201669, Test Acc: 89.54 %\n",
      "90 epoch end, loss: 0.203201, Test Acc: 84.72 %\n",
      "91 epoch end, loss: 0.193790, Test Acc: 88.50 %\n",
      "92 epoch end, loss: 0.196645, Test Acc: 87.61 %\n",
      "93 epoch end, loss: 0.194493, Test Acc: 89.41 %\n",
      "94 epoch end, loss: 0.197846, Test Acc: 89.08 %\n",
      "95 epoch end, loss: 0.192830, Test Acc: 85.98 %\n",
      "96 epoch end, loss: 0.197945, Test Acc: 87.69 %\n",
      "97 epoch end, loss: 0.196075, Test Acc: 89.56 %\n",
      "98 epoch end, loss: 0.195494, Test Acc: 89.72 %\n",
      "99 epoch end, loss: 0.193810, Test Acc: 91.02 %\n",
      "100 epoch end, loss: 0.193209, Test Acc: 88.44 %\n",
      "101 epoch end, loss: 0.194985, Test Acc: 90.25 %\n",
      "102 epoch end, loss: 0.195298, Test Acc: 88.48 %\n",
      "103 epoch end, loss: 0.197370, Test Acc: 90.71 %\n",
      "104 epoch end, loss: 0.192745, Test Acc: 88.26 %\n",
      "105 epoch end, loss: 0.194382, Test Acc: 86.97 %\n",
      "106 epoch end, loss: 0.192410, Test Acc: 89.29 %\n",
      "107 epoch end, loss: 0.188563, Test Acc: 91.56 %\n",
      "108 epoch end, loss: 0.194192, Test Acc: 87.66 %\n",
      "109 epoch end, loss: 0.191054, Test Acc: 87.09 %\n",
      "110 epoch end, loss: 0.191819, Test Acc: 89.82 %\n",
      "111 epoch end, loss: 0.192050, Test Acc: 89.44 %\n",
      "112 epoch end, loss: 0.193723, Test Acc: 89.87 %\n",
      "113 epoch end, loss: 0.187837, Test Acc: 86.80 %\n",
      "114 epoch end, loss: 0.189717, Test Acc: 89.20 %\n",
      "115 epoch end, loss: 0.185669, Test Acc: 89.30 %\n",
      "116 epoch end, loss: 0.190928, Test Acc: 89.79 %\n",
      "117 epoch end, loss: 0.186403, Test Acc: 90.02 %\n",
      "118 epoch end, loss: 0.190686, Test Acc: 88.78 %\n",
      "119 epoch end, loss: 0.186908, Test Acc: 87.07 %\n",
      "120 epoch end, loss: 0.193728, Test Acc: 89.09 %\n",
      "121 epoch end, loss: 0.186558, Test Acc: 89.91 %\n",
      "122 epoch end, loss: 0.183709, Test Acc: 88.44 %\n",
      "123 epoch end, loss: 0.190171, Test Acc: 88.27 %\n",
      "124 epoch end, loss: 0.185264, Test Acc: 89.06 %\n",
      "125 epoch end, loss: 0.189179, Test Acc: 89.00 %\n",
      "126 epoch end, loss: 0.188091, Test Acc: 86.79 %\n",
      "127 epoch end, loss: 0.188623, Test Acc: 88.15 %\n",
      "128 epoch end, loss: 0.186371, Test Acc: 89.47 %\n",
      "129 epoch end, loss: 0.186422, Test Acc: 88.23 %\n",
      "130 epoch end, loss: 0.189331, Test Acc: 89.08 %\n",
      "131 epoch end, loss: 0.186186, Test Acc: 89.64 %\n",
      "132 epoch end, loss: 0.183749, Test Acc: 90.16 %\n",
      "133 epoch end, loss: 0.182799, Test Acc: 89.44 %\n",
      "134 epoch end, loss: 0.180622, Test Acc: 87.47 %\n",
      "135 epoch end, loss: 0.186911, Test Acc: 88.58 %\n",
      "136 epoch end, loss: 0.182107, Test Acc: 88.37 %\n",
      "137 epoch end, loss: 0.182751, Test Acc: 89.75 %\n",
      "138 epoch end, loss: 0.184314, Test Acc: 88.90 %\n",
      "139 epoch end, loss: 0.184626, Test Acc: 89.07 %\n",
      "140 epoch end, loss: 0.186172, Test Acc: 88.60 %\n",
      "141 epoch end, loss: 0.181368, Test Acc: 86.19 %\n",
      "142 epoch end, loss: 0.182541, Test Acc: 88.41 %\n",
      "143 epoch end, loss: 0.184159, Test Acc: 89.57 %\n",
      "144 epoch end, loss: 0.183519, Test Acc: 91.01 %\n",
      "145 epoch end, loss: 0.183786, Test Acc: 90.07 %\n",
      "146 epoch end, loss: 0.185435, Test Acc: 88.58 %\n",
      "147 epoch end, loss: 0.178880, Test Acc: 87.75 %\n",
      "148 epoch end, loss: 0.184905, Test Acc: 88.76 %\n",
      "149 epoch end, loss: 0.179310, Test Acc: 88.30 %\n",
      "150 epoch end, loss: 0.181320, Test Acc: 89.51 %\n",
      "151 epoch end, loss: 0.082959, Test Acc: 94.35 %\n",
      "152 epoch end, loss: 0.051546, Test Acc: 94.46 %\n",
      "153 epoch end, loss: 0.042548, Test Acc: 94.66 %\n",
      "154 epoch end, loss: 0.035747, Test Acc: 94.47 %\n",
      "155 epoch end, loss: 0.031565, Test Acc: 94.40 %\n",
      "156 epoch end, loss: 0.027416, Test Acc: 94.45 %\n",
      "157 epoch end, loss: 0.026014, Test Acc: 94.43 %\n",
      "158 epoch end, loss: 0.024493, Test Acc: 94.49 %\n",
      "159 epoch end, loss: 0.022307, Test Acc: 94.31 %\n",
      "160 epoch end, loss: 0.021417, Test Acc: 93.98 %\n",
      "161 epoch end, loss: 0.023462, Test Acc: 94.40 %\n",
      "162 epoch end, loss: 0.021106, Test Acc: 94.49 %\n",
      "163 epoch end, loss: 0.020498, Test Acc: 94.02 %\n",
      "164 epoch end, loss: 0.021944, Test Acc: 94.14 %\n",
      "165 epoch end, loss: 0.022565, Test Acc: 94.12 %\n",
      "166 epoch end, loss: 0.020737, Test Acc: 94.02 %\n",
      "167 epoch end, loss: 0.022401, Test Acc: 93.80 %\n",
      "168 epoch end, loss: 0.021268, Test Acc: 93.84 %\n",
      "169 epoch end, loss: 0.024364, Test Acc: 94.10 %\n",
      "170 epoch end, loss: 0.022110, Test Acc: 93.80 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 epoch end, loss: 0.024509, Test Acc: 93.75 %\n",
      "172 epoch end, loss: 0.023579, Test Acc: 93.75 %\n",
      "173 epoch end, loss: 0.023717, Test Acc: 94.16 %\n",
      "174 epoch end, loss: 0.024998, Test Acc: 93.87 %\n",
      "175 epoch end, loss: 0.028205, Test Acc: 93.36 %\n",
      "176 epoch end, loss: 0.031664, Test Acc: 93.28 %\n",
      "177 epoch end, loss: 0.034763, Test Acc: 93.43 %\n",
      "178 epoch end, loss: 0.029694, Test Acc: 92.72 %\n",
      "179 epoch end, loss: 0.030958, Test Acc: 93.78 %\n",
      "180 epoch end, loss: 0.036106, Test Acc: 93.13 %\n",
      "181 epoch end, loss: 0.033048, Test Acc: 93.43 %\n",
      "182 epoch end, loss: 0.034024, Test Acc: 93.42 %\n",
      "183 epoch end, loss: 0.038320, Test Acc: 93.35 %\n",
      "184 epoch end, loss: 0.037832, Test Acc: 93.44 %\n",
      "185 epoch end, loss: 0.038151, Test Acc: 92.71 %\n",
      "186 epoch end, loss: 0.036169, Test Acc: 93.34 %\n",
      "187 epoch end, loss: 0.040683, Test Acc: 93.30 %\n",
      "188 epoch end, loss: 0.042282, Test Acc: 93.08 %\n",
      "189 epoch end, loss: 0.038516, Test Acc: 93.26 %\n",
      "190 epoch end, loss: 0.043921, Test Acc: 93.08 %\n",
      "191 epoch end, loss: 0.042370, Test Acc: 93.18 %\n",
      "192 epoch end, loss: 0.037714, Test Acc: 92.81 %\n",
      "193 epoch end, loss: 0.040260, Test Acc: 93.38 %\n",
      "194 epoch end, loss: 0.040071, Test Acc: 92.85 %\n",
      "195 epoch end, loss: 0.040593, Test Acc: 92.72 %\n",
      "196 epoch end, loss: 0.047529, Test Acc: 93.04 %\n",
      "197 epoch end, loss: 0.048427, Test Acc: 92.44 %\n",
      "198 epoch end, loss: 0.041786, Test Acc: 92.63 %\n",
      "199 epoch end, loss: 0.040529, Test Acc: 92.35 %\n",
      "200 epoch end, loss: 0.044583, Test Acc: 92.89 %\n",
      "201 epoch end, loss: 0.043931, Test Acc: 92.59 %\n",
      "202 epoch end, loss: 0.046371, Test Acc: 92.28 %\n",
      "203 epoch end, loss: 0.046750, Test Acc: 92.95 %\n",
      "204 epoch end, loss: 0.044626, Test Acc: 92.85 %\n",
      "205 epoch end, loss: 0.050056, Test Acc: 93.19 %\n",
      "206 epoch end, loss: 0.041357, Test Acc: 92.37 %\n",
      "207 epoch end, loss: 0.049745, Test Acc: 92.97 %\n",
      "208 epoch end, loss: 0.046636, Test Acc: 91.93 %\n",
      "209 epoch end, loss: 0.041935, Test Acc: 93.23 %\n",
      "210 epoch end, loss: 0.049831, Test Acc: 92.79 %\n",
      "211 epoch end, loss: 0.046264, Test Acc: 91.67 %\n",
      "212 epoch end, loss: 0.048929, Test Acc: 92.83 %\n",
      "213 epoch end, loss: 0.042261, Test Acc: 93.03 %\n",
      "214 epoch end, loss: 0.046759, Test Acc: 92.82 %\n",
      "215 epoch end, loss: 0.043492, Test Acc: 93.24 %\n",
      "216 epoch end, loss: 0.040894, Test Acc: 92.64 %\n",
      "217 epoch end, loss: 0.046272, Test Acc: 93.11 %\n",
      "218 epoch end, loss: 0.047908, Test Acc: 93.09 %\n",
      "219 epoch end, loss: 0.055099, Test Acc: 92.51 %\n",
      "220 epoch end, loss: 0.055143, Test Acc: 92.73 %\n",
      "221 epoch end, loss: 0.042415, Test Acc: 92.14 %\n",
      "222 epoch end, loss: 0.044251, Test Acc: 93.07 %\n",
      "223 epoch end, loss: 0.042524, Test Acc: 92.75 %\n",
      "224 epoch end, loss: 0.046769, Test Acc: 92.93 %\n",
      "225 epoch end, loss: 0.040507, Test Acc: 93.24 %\n",
      "226 epoch end, loss: 0.019184, Test Acc: 94.45 %\n",
      "227 epoch end, loss: 0.009311, Test Acc: 94.64 %\n",
      "228 epoch end, loss: 0.007671, Test Acc: 94.56 %\n",
      "229 epoch end, loss: 0.006996, Test Acc: 94.79 %\n",
      "230 epoch end, loss: 0.006144, Test Acc: 94.79 %\n",
      "231 epoch end, loss: 0.005586, Test Acc: 94.79 %\n",
      "232 epoch end, loss: 0.005208, Test Acc: 94.89 %\n",
      "233 epoch end, loss: 0.004612, Test Acc: 94.77 %\n",
      "234 epoch end, loss: 0.004326, Test Acc: 94.79 %\n",
      "235 epoch end, loss: 0.004705, Test Acc: 95.12 %\n",
      "236 epoch end, loss: 0.004229, Test Acc: 94.91 %\n",
      "237 epoch end, loss: 0.004281, Test Acc: 94.89 %\n",
      "238 epoch end, loss: 0.004096, Test Acc: 94.92 %\n",
      "239 epoch end, loss: 0.003698, Test Acc: 94.85 %\n",
      "240 epoch end, loss: 0.003448, Test Acc: 95.05 %\n",
      "241 epoch end, loss: 0.003476, Test Acc: 94.89 %\n",
      "242 epoch end, loss: 0.003224, Test Acc: 94.98 %\n",
      "243 epoch end, loss: 0.003435, Test Acc: 95.06 %\n",
      "244 epoch end, loss: 0.003118, Test Acc: 95.03 %\n",
      "245 epoch end, loss: 0.003032, Test Acc: 95.06 %\n",
      "246 epoch end, loss: 0.003058, Test Acc: 94.93 %\n",
      "247 epoch end, loss: 0.002915, Test Acc: 95.02 %\n",
      "248 epoch end, loss: 0.002604, Test Acc: 94.89 %\n",
      "249 epoch end, loss: 0.002815, Test Acc: 94.99 %\n",
      "250 epoch end, loss: 0.002721, Test Acc: 94.95 %\n",
      "251 epoch end, loss: 0.002846, Test Acc: 94.95 %\n",
      "252 epoch end, loss: 0.002489, Test Acc: 95.05 %\n",
      "253 epoch end, loss: 0.002358, Test Acc: 95.15 %\n",
      "254 epoch end, loss: 0.002332, Test Acc: 95.02 %\n",
      "255 epoch end, loss: 0.002510, Test Acc: 95.09 %\n",
      "256 epoch end, loss: 0.002300, Test Acc: 94.99 %\n",
      "257 epoch end, loss: 0.002545, Test Acc: 94.98 %\n",
      "258 epoch end, loss: 0.002355, Test Acc: 94.99 %\n",
      "259 epoch end, loss: 0.002525, Test Acc: 95.09 %\n",
      "260 epoch end, loss: 0.002086, Test Acc: 95.01 %\n",
      "261 epoch end, loss: 0.002590, Test Acc: 95.01 %\n",
      "262 epoch end, loss: 0.002479, Test Acc: 95.06 %\n",
      "263 epoch end, loss: 0.002597, Test Acc: 94.88 %\n",
      "264 epoch end, loss: 0.002349, Test Acc: 95.01 %\n",
      "265 epoch end, loss: 0.002230, Test Acc: 95.00 %\n",
      "266 epoch end, loss: 0.002266, Test Acc: 94.92 %\n",
      "267 epoch end, loss: 0.002214, Test Acc: 94.89 %\n",
      "268 epoch end, loss: 0.002303, Test Acc: 94.84 %\n",
      "269 epoch end, loss: 0.002070, Test Acc: 95.01 %\n",
      "270 epoch end, loss: 0.001932, Test Acc: 95.12 %\n",
      "271 epoch end, loss: 0.002074, Test Acc: 94.90 %\n",
      "272 epoch end, loss: 0.001999, Test Acc: 95.06 %\n",
      "273 epoch end, loss: 0.002298, Test Acc: 94.90 %\n",
      "274 epoch end, loss: 0.002152, Test Acc: 94.90 %\n",
      "275 epoch end, loss: 0.002128, Test Acc: 94.97 %\n",
      "276 epoch end, loss: 0.002151, Test Acc: 94.96 %\n",
      "277 epoch end, loss: 0.001991, Test Acc: 95.14 %\n",
      "278 epoch end, loss: 0.001973, Test Acc: 94.83 %\n",
      "279 epoch end, loss: 0.001998, Test Acc: 95.00 %\n",
      "280 epoch end, loss: 0.002448, Test Acc: 94.92 %\n",
      "281 epoch end, loss: 0.002248, Test Acc: 94.97 %\n",
      "282 epoch end, loss: 0.002092, Test Acc: 95.06 %\n",
      "283 epoch end, loss: 0.001914, Test Acc: 95.15 %\n",
      "284 epoch end, loss: 0.001846, Test Acc: 95.17 %\n",
      "285 epoch end, loss: 0.001967, Test Acc: 95.16 %\n",
      "286 epoch end, loss: 0.001703, Test Acc: 95.08 %\n",
      "287 epoch end, loss: 0.001935, Test Acc: 95.00 %\n",
      "288 epoch end, loss: 0.001982, Test Acc: 95.14 %\n",
      "289 epoch end, loss: 0.001910, Test Acc: 95.23 %\n",
      "290 epoch end, loss: 0.001754, Test Acc: 95.11 %\n",
      "291 epoch end, loss: 0.001779, Test Acc: 95.27 %\n",
      "292 epoch end, loss: 0.001767, Test Acc: 94.98 %\n",
      "293 epoch end, loss: 0.002021, Test Acc: 95.09 %\n",
      "294 epoch end, loss: 0.002931, Test Acc: 95.05 %\n",
      "295 epoch end, loss: 0.002072, Test Acc: 95.02 %\n",
      "296 epoch end, loss: 0.001934, Test Acc: 94.99 %\n",
      "297 epoch end, loss: 0.001758, Test Acc: 95.12 %\n",
      "298 epoch end, loss: 0.001769, Test Acc: 95.07 %\n",
      "299 epoch end, loss: 0.002044, Test Acc: 95.30 %\n",
      "300 epoch end, loss: 0.001630, Test Acc: 95.20 %\n",
      "\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    net.TrainMode()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        #scheduler.step()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = (running_loss * i + loss.cpu().data.numpy()) / (i+1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.TestMode()\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(Variable(images.cuda()))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "        \n",
    "    print('%d epoch end, loss: %3.6f, Test Acc: %4.2f %%' %(epoch + 1, running_loss, 100 * correct / total))\n",
    "    \n",
    "print('\\nTraining is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning (KD + Cross-entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.20 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "net.TestMode()\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.GetStateDict(), pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'ConvBlock'],\n",
       " [[BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'DenseBlock'],\n",
       " [Conv2d(216, 108, kernel_size=(1, 1), stride=(1, 1)), 'ConvBlock'],\n",
       " AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True),\n",
       " [[BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(228, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(252, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(264, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(276, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'DenseBlock'],\n",
       " [Conv2d(300, 150, kernel_size=(1, 1), stride=(1, 1)), 'ConvBlock'],\n",
       " AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True),\n",
       " [[BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(150, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(162, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(162, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(174, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(186, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(198, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(198, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(210, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(210, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(222, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(222, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(234, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(234, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(246, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(246, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(258, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(258, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(270, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(270, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(282, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(282, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(294, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(294, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(306, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(306, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(318, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(318, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  [BatchNorm2d(330, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(330, 48, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True),\n",
       "   ReLU(inplace),\n",
       "   Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)],\n",
       "  BatchNorm2d(342, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'DenseBlock'],\n",
       " AvgPool2d(kernel_size=8, stride=8, padding=0, ceil_mode=False, count_include_pad=True),\n",
       " 'Flatten',\n",
       " [Linear(in_features=342, out_features=10, bias=True), 'FCBlock']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.blocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
