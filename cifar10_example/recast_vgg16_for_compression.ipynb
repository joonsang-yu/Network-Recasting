{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "from model_generator import ModelGenerator\n",
    "from net import Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dropout_on = False\n",
    "batchnorm_on = True \n",
    "\n",
    "scheduler_step_size = 20\n",
    "\n",
    "## for recasting\n",
    "\n",
    "lr_recasting = 0.001\n",
    "num_epoch_recasting = 60\n",
    "\n",
    "## for fine tune\n",
    "\n",
    "lr_fine_tune = 0.001\n",
    "num_epoch_fine_tune = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen = ModelGenerator(dropout = dropout_on, batchnorm = batchnorm_on)\n",
    "\n",
    "model_gen.CifarVgg16Config(cifar = 10)\n",
    "\n",
    "# Recasting block\n",
    "# 0-13: conv block\n",
    "recasting_block_indices = range(0, 13)\n",
    "target_block_type = 'ConvBlock'\n",
    "\n",
    "# Compression rate\n",
    "# the number of filters decreased to [compression_rate]\n",
    "\n",
    "compression_ratio = 0.4\n",
    "\n",
    "## file path\n",
    "pretrained_model = './cifar10_vgg16_pretrained.pth'\n",
    "compressed_model = './cifar10_vgg16_to_convenet.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomCrop(32, 4),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model (teacher network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 93.01 %\n"
     ]
    }
   ],
   "source": [
    "model = model_gen.GetCifarVgg16()\n",
    "teacher = Net(model)\n",
    "\n",
    "state = torch.load(pretrained_model)\n",
    "teacher.LoadFromStateDict(state)\n",
    "\n",
    "teacher.Gpu()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "teacher.TestMode()\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = teacher(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define student network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_gen.GetCifarVgg16()\n",
    "student = Net(model)\n",
    "\n",
    "state = torch.load(pretrained_model)\n",
    "student.LoadFromStateDict(state)\n",
    "\n",
    "student.Gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 93.01 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "student.TestMode()\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = student(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential recasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block 0 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.017315, Test Acc: 92.67 %\n",
      "(2/60) epoch end, loss: 0.002007, Test Acc: 92.75 %\n",
      "(3/60) epoch end, loss: 0.001264, Test Acc: 92.86 %\n",
      "(4/60) epoch end, loss: 0.000794, Test Acc: 92.82 %\n",
      "(5/60) epoch end, loss: 0.000622, Test Acc: 92.90 %\n",
      "(6/60) epoch end, loss: 0.000568, Test Acc: 92.90 %\n",
      "(7/60) epoch end, loss: 0.000529, Test Acc: 92.88 %\n",
      "(8/60) epoch end, loss: 0.000502, Test Acc: 92.92 %\n",
      "(9/60) epoch end, loss: 0.000484, Test Acc: 92.93 %\n",
      "(10/60) epoch end, loss: 0.000475, Test Acc: 93.09 %\n",
      "(11/60) epoch end, loss: 0.000460, Test Acc: 93.07 %\n",
      "(12/60) epoch end, loss: 0.000447, Test Acc: 92.91 %\n",
      "(13/60) epoch end, loss: 0.000455, Test Acc: 92.81 %\n",
      "(14/60) epoch end, loss: 0.000435, Test Acc: 92.89 %\n",
      "(15/60) epoch end, loss: 0.000441, Test Acc: 93.09 %\n",
      "(16/60) epoch end, loss: 0.000436, Test Acc: 92.97 %\n",
      "(17/60) epoch end, loss: 0.000428, Test Acc: 92.98 %\n",
      "(18/60) epoch end, loss: 0.000424, Test Acc: 92.87 %\n",
      "(19/60) epoch end, loss: 0.000434, Test Acc: 93.01 %\n",
      "(20/60) epoch end, loss: 0.000422, Test Acc: 92.92 %\n",
      "(21/60) epoch end, loss: 0.000391, Test Acc: 92.98 %\n",
      "(22/60) epoch end, loss: 0.000377, Test Acc: 92.96 %\n",
      "(23/60) epoch end, loss: 0.000391, Test Acc: 92.99 %\n",
      "(24/60) epoch end, loss: 0.000391, Test Acc: 92.96 %\n",
      "(25/60) epoch end, loss: 0.000384, Test Acc: 93.00 %\n",
      "(26/60) epoch end, loss: 0.000382, Test Acc: 92.99 %\n",
      "(27/60) epoch end, loss: 0.000388, Test Acc: 92.96 %\n",
      "(28/60) epoch end, loss: 0.000386, Test Acc: 92.99 %\n",
      "(29/60) epoch end, loss: 0.000388, Test Acc: 92.96 %\n",
      "(30/60) epoch end, loss: 0.000389, Test Acc: 93.01 %\n",
      "(31/60) epoch end, loss: 0.000379, Test Acc: 92.92 %\n",
      "(32/60) epoch end, loss: 0.000390, Test Acc: 92.96 %\n",
      "(33/60) epoch end, loss: 0.000378, Test Acc: 92.95 %\n",
      "(34/60) epoch end, loss: 0.000390, Test Acc: 92.98 %\n",
      "(35/60) epoch end, loss: 0.000384, Test Acc: 93.01 %\n",
      "(36/60) epoch end, loss: 0.000393, Test Acc: 93.03 %\n",
      "(37/60) epoch end, loss: 0.000384, Test Acc: 93.01 %\n",
      "(38/60) epoch end, loss: 0.000381, Test Acc: 93.06 %\n",
      "(39/60) epoch end, loss: 0.000385, Test Acc: 92.93 %\n",
      "(40/60) epoch end, loss: 0.000386, Test Acc: 92.95 %\n",
      "(41/60) epoch end, loss: 0.000379, Test Acc: 92.99 %\n",
      "(42/60) epoch end, loss: 0.000382, Test Acc: 93.02 %\n",
      "(43/60) epoch end, loss: 0.000384, Test Acc: 92.96 %\n",
      "(44/60) epoch end, loss: 0.000388, Test Acc: 92.98 %\n",
      "(45/60) epoch end, loss: 0.000381, Test Acc: 92.92 %\n",
      "(46/60) epoch end, loss: 0.000386, Test Acc: 92.94 %\n",
      "(47/60) epoch end, loss: 0.000386, Test Acc: 92.97 %\n",
      "(48/60) epoch end, loss: 0.000384, Test Acc: 92.99 %\n",
      "(49/60) epoch end, loss: 0.000384, Test Acc: 92.91 %\n",
      "(50/60) epoch end, loss: 0.000380, Test Acc: 92.95 %\n",
      "(51/60) epoch end, loss: 0.000379, Test Acc: 92.98 %\n",
      "(52/60) epoch end, loss: 0.000377, Test Acc: 92.93 %\n",
      "(53/60) epoch end, loss: 0.000386, Test Acc: 92.98 %\n",
      "(54/60) epoch end, loss: 0.000386, Test Acc: 92.97 %\n",
      "(55/60) epoch end, loss: 0.000371, Test Acc: 93.03 %\n",
      "(56/60) epoch end, loss: 0.000389, Test Acc: 92.97 %\n",
      "(57/60) epoch end, loss: 0.000380, Test Acc: 92.95 %\n",
      "(58/60) epoch end, loss: 0.000377, Test Acc: 92.99 %\n",
      "(59/60) epoch end, loss: 0.000380, Test Acc: 92.99 %\n",
      "(60/60) epoch end, loss: 0.000376, Test Acc: 93.03 %\n",
      "\n",
      "Block 1 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.017108, Test Acc: 90.86 %\n",
      "(2/60) epoch end, loss: 0.004294, Test Acc: 92.01 %\n",
      "(3/60) epoch end, loss: 0.003269, Test Acc: 92.29 %\n",
      "(4/60) epoch end, loss: 0.002814, Test Acc: 92.40 %\n",
      "(5/60) epoch end, loss: 0.002606, Test Acc: 92.51 %\n",
      "(6/60) epoch end, loss: 0.002481, Test Acc: 92.39 %\n",
      "(7/60) epoch end, loss: 0.002415, Test Acc: 92.48 %\n",
      "(8/60) epoch end, loss: 0.002348, Test Acc: 92.62 %\n",
      "(9/60) epoch end, loss: 0.002317, Test Acc: 92.47 %\n",
      "(10/60) epoch end, loss: 0.002282, Test Acc: 92.53 %\n",
      "(11/60) epoch end, loss: 0.002264, Test Acc: 92.38 %\n",
      "(12/60) epoch end, loss: 0.002247, Test Acc: 92.59 %\n",
      "(13/60) epoch end, loss: 0.002232, Test Acc: 92.30 %\n",
      "(14/60) epoch end, loss: 0.002210, Test Acc: 92.63 %\n",
      "(15/60) epoch end, loss: 0.002199, Test Acc: 92.45 %\n",
      "(16/60) epoch end, loss: 0.002192, Test Acc: 92.55 %\n",
      "(17/60) epoch end, loss: 0.002186, Test Acc: 92.57 %\n",
      "(18/60) epoch end, loss: 0.002181, Test Acc: 92.47 %\n",
      "(19/60) epoch end, loss: 0.002176, Test Acc: 92.53 %\n",
      "(20/60) epoch end, loss: 0.002173, Test Acc: 92.42 %\n",
      "(21/60) epoch end, loss: 0.002124, Test Acc: 92.52 %\n",
      "(22/60) epoch end, loss: 0.002121, Test Acc: 92.43 %\n",
      "(23/60) epoch end, loss: 0.002124, Test Acc: 92.50 %\n",
      "(24/60) epoch end, loss: 0.002125, Test Acc: 92.53 %\n",
      "(25/60) epoch end, loss: 0.002122, Test Acc: 92.47 %\n",
      "(26/60) epoch end, loss: 0.002114, Test Acc: 92.51 %\n",
      "(27/60) epoch end, loss: 0.002122, Test Acc: 92.48 %\n",
      "(28/60) epoch end, loss: 0.002118, Test Acc: 92.57 %\n",
      "(29/60) epoch end, loss: 0.002116, Test Acc: 92.44 %\n",
      "(30/60) epoch end, loss: 0.002116, Test Acc: 92.50 %\n",
      "(31/60) epoch end, loss: 0.002115, Test Acc: 92.44 %\n",
      "(32/60) epoch end, loss: 0.002116, Test Acc: 92.57 %\n",
      "(33/60) epoch end, loss: 0.002113, Test Acc: 92.52 %\n",
      "(34/60) epoch end, loss: 0.002112, Test Acc: 92.57 %\n",
      "(35/60) epoch end, loss: 0.002113, Test Acc: 92.52 %\n",
      "(36/60) epoch end, loss: 0.002116, Test Acc: 92.56 %\n",
      "(37/60) epoch end, loss: 0.002111, Test Acc: 92.52 %\n",
      "(38/60) epoch end, loss: 0.002116, Test Acc: 92.56 %\n",
      "(39/60) epoch end, loss: 0.002116, Test Acc: 92.51 %\n",
      "(40/60) epoch end, loss: 0.002112, Test Acc: 92.54 %\n",
      "(41/60) epoch end, loss: 0.002106, Test Acc: 92.46 %\n",
      "(42/60) epoch end, loss: 0.002106, Test Acc: 92.49 %\n",
      "(43/60) epoch end, loss: 0.002109, Test Acc: 92.59 %\n",
      "(44/60) epoch end, loss: 0.002108, Test Acc: 92.51 %\n",
      "(45/60) epoch end, loss: 0.002103, Test Acc: 92.50 %\n",
      "(46/60) epoch end, loss: 0.002107, Test Acc: 92.52 %\n",
      "(47/60) epoch end, loss: 0.002105, Test Acc: 92.47 %\n",
      "(48/60) epoch end, loss: 0.002106, Test Acc: 92.51 %\n",
      "(49/60) epoch end, loss: 0.002107, Test Acc: 92.49 %\n",
      "(50/60) epoch end, loss: 0.002105, Test Acc: 92.50 %\n",
      "(51/60) epoch end, loss: 0.002108, Test Acc: 92.52 %\n",
      "(52/60) epoch end, loss: 0.002110, Test Acc: 92.47 %\n",
      "(53/60) epoch end, loss: 0.002105, Test Acc: 92.51 %\n",
      "(54/60) epoch end, loss: 0.002107, Test Acc: 92.53 %\n",
      "(55/60) epoch end, loss: 0.002106, Test Acc: 92.54 %\n",
      "(56/60) epoch end, loss: 0.002109, Test Acc: 92.56 %\n",
      "(57/60) epoch end, loss: 0.002105, Test Acc: 92.51 %\n",
      "(58/60) epoch end, loss: 0.002105, Test Acc: 92.50 %\n",
      "(59/60) epoch end, loss: 0.002108, Test Acc: 92.53 %\n",
      "(60/60) epoch end, loss: 0.002102, Test Acc: 92.53 %\n",
      "\n",
      "Block 2 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.012370, Test Acc: 90.87 %\n",
      "(2/60) epoch end, loss: 0.004644, Test Acc: 91.53 %\n",
      "(3/60) epoch end, loss: 0.003949, Test Acc: 92.15 %\n",
      "(4/60) epoch end, loss: 0.003632, Test Acc: 92.17 %\n",
      "(5/60) epoch end, loss: 0.003433, Test Acc: 92.10 %\n",
      "(6/60) epoch end, loss: 0.003301, Test Acc: 92.21 %\n",
      "(7/60) epoch end, loss: 0.003209, Test Acc: 92.11 %\n",
      "(8/60) epoch end, loss: 0.003140, Test Acc: 92.35 %\n",
      "(9/60) epoch end, loss: 0.003089, Test Acc: 92.13 %\n",
      "(10/60) epoch end, loss: 0.003051, Test Acc: 92.29 %\n",
      "(11/60) epoch end, loss: 0.003020, Test Acc: 92.06 %\n",
      "(12/60) epoch end, loss: 0.003003, Test Acc: 92.08 %\n",
      "(13/60) epoch end, loss: 0.002990, Test Acc: 92.25 %\n",
      "(14/60) epoch end, loss: 0.002976, Test Acc: 92.21 %\n",
      "(15/60) epoch end, loss: 0.002961, Test Acc: 91.99 %\n",
      "(16/60) epoch end, loss: 0.002955, Test Acc: 92.28 %\n",
      "(17/60) epoch end, loss: 0.002943, Test Acc: 92.04 %\n",
      "(18/60) epoch end, loss: 0.002936, Test Acc: 92.12 %\n",
      "(19/60) epoch end, loss: 0.002924, Test Acc: 92.06 %\n",
      "(20/60) epoch end, loss: 0.002924, Test Acc: 92.17 %\n",
      "(21/60) epoch end, loss: 0.002871, Test Acc: 92.32 %\n",
      "(22/60) epoch end, loss: 0.002868, Test Acc: 92.40 %\n",
      "(23/60) epoch end, loss: 0.002863, Test Acc: 92.33 %\n",
      "(24/60) epoch end, loss: 0.002862, Test Acc: 92.38 %\n",
      "(25/60) epoch end, loss: 0.002861, Test Acc: 92.31 %\n",
      "(26/60) epoch end, loss: 0.002863, Test Acc: 92.36 %\n",
      "(27/60) epoch end, loss: 0.002859, Test Acc: 92.27 %\n",
      "(28/60) epoch end, loss: 0.002860, Test Acc: 92.27 %\n",
      "(29/60) epoch end, loss: 0.002860, Test Acc: 92.30 %\n",
      "(30/60) epoch end, loss: 0.002855, Test Acc: 92.36 %\n",
      "(31/60) epoch end, loss: 0.002853, Test Acc: 92.41 %\n",
      "(32/60) epoch end, loss: 0.002856, Test Acc: 92.34 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33/60) epoch end, loss: 0.002855, Test Acc: 92.27 %\n",
      "(34/60) epoch end, loss: 0.002853, Test Acc: 92.32 %\n",
      "(35/60) epoch end, loss: 0.002852, Test Acc: 92.36 %\n",
      "(36/60) epoch end, loss: 0.002852, Test Acc: 92.34 %\n",
      "(37/60) epoch end, loss: 0.002852, Test Acc: 92.39 %\n",
      "(38/60) epoch end, loss: 0.002852, Test Acc: 92.33 %\n",
      "(39/60) epoch end, loss: 0.002851, Test Acc: 92.43 %\n",
      "(40/60) epoch end, loss: 0.002850, Test Acc: 92.35 %\n",
      "(41/60) epoch end, loss: 0.002843, Test Acc: 92.32 %\n",
      "(42/60) epoch end, loss: 0.002840, Test Acc: 92.40 %\n",
      "(43/60) epoch end, loss: 0.002843, Test Acc: 92.34 %\n",
      "(44/60) epoch end, loss: 0.002842, Test Acc: 92.32 %\n",
      "(45/60) epoch end, loss: 0.002843, Test Acc: 92.47 %\n",
      "(46/60) epoch end, loss: 0.002843, Test Acc: 92.31 %\n",
      "(47/60) epoch end, loss: 0.002842, Test Acc: 92.36 %\n",
      "(48/60) epoch end, loss: 0.002846, Test Acc: 92.33 %\n",
      "(49/60) epoch end, loss: 0.002844, Test Acc: 92.38 %\n",
      "(50/60) epoch end, loss: 0.002843, Test Acc: 92.37 %\n",
      "(51/60) epoch end, loss: 0.002839, Test Acc: 92.28 %\n",
      "(52/60) epoch end, loss: 0.002840, Test Acc: 92.35 %\n",
      "(53/60) epoch end, loss: 0.002842, Test Acc: 92.32 %\n",
      "(54/60) epoch end, loss: 0.002840, Test Acc: 92.35 %\n",
      "(55/60) epoch end, loss: 0.002843, Test Acc: 92.39 %\n",
      "(56/60) epoch end, loss: 0.002843, Test Acc: 92.36 %\n",
      "(57/60) epoch end, loss: 0.002843, Test Acc: 92.35 %\n",
      "(58/60) epoch end, loss: 0.002842, Test Acc: 92.32 %\n",
      "(59/60) epoch end, loss: 0.002842, Test Acc: 92.31 %\n",
      "(60/60) epoch end, loss: 0.002845, Test Acc: 92.33 %\n",
      "\n",
      "Block 3 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.010408, Test Acc: 89.41 %\n",
      "(2/60) epoch end, loss: 0.005034, Test Acc: 90.64 %\n",
      "(3/60) epoch end, loss: 0.004491, Test Acc: 90.93 %\n",
      "(4/60) epoch end, loss: 0.004244, Test Acc: 90.91 %\n",
      "(5/60) epoch end, loss: 0.004080, Test Acc: 91.21 %\n",
      "(6/60) epoch end, loss: 0.003982, Test Acc: 90.78 %\n",
      "(7/60) epoch end, loss: 0.003908, Test Acc: 90.93 %\n",
      "(8/60) epoch end, loss: 0.003850, Test Acc: 91.29 %\n",
      "(9/60) epoch end, loss: 0.003791, Test Acc: 91.18 %\n",
      "(10/60) epoch end, loss: 0.003723, Test Acc: 90.74 %\n",
      "(11/60) epoch end, loss: 0.003681, Test Acc: 91.31 %\n",
      "(12/60) epoch end, loss: 0.003643, Test Acc: 91.50 %\n",
      "(13/60) epoch end, loss: 0.003608, Test Acc: 91.34 %\n",
      "(14/60) epoch end, loss: 0.003588, Test Acc: 91.28 %\n",
      "(15/60) epoch end, loss: 0.003569, Test Acc: 91.27 %\n",
      "(16/60) epoch end, loss: 0.003557, Test Acc: 91.47 %\n",
      "(17/60) epoch end, loss: 0.003544, Test Acc: 91.39 %\n",
      "(18/60) epoch end, loss: 0.003535, Test Acc: 91.55 %\n",
      "(19/60) epoch end, loss: 0.003517, Test Acc: 91.63 %\n",
      "(20/60) epoch end, loss: 0.003511, Test Acc: 91.53 %\n",
      "(21/60) epoch end, loss: 0.003447, Test Acc: 91.79 %\n",
      "(22/60) epoch end, loss: 0.003441, Test Acc: 91.65 %\n",
      "(23/60) epoch end, loss: 0.003436, Test Acc: 91.81 %\n",
      "(24/60) epoch end, loss: 0.003440, Test Acc: 91.70 %\n",
      "(25/60) epoch end, loss: 0.003441, Test Acc: 91.74 %\n",
      "(26/60) epoch end, loss: 0.003437, Test Acc: 91.69 %\n",
      "(27/60) epoch end, loss: 0.003435, Test Acc: 91.63 %\n",
      "(28/60) epoch end, loss: 0.003439, Test Acc: 91.73 %\n",
      "(29/60) epoch end, loss: 0.003437, Test Acc: 91.70 %\n",
      "(30/60) epoch end, loss: 0.003433, Test Acc: 91.75 %\n",
      "(31/60) epoch end, loss: 0.003435, Test Acc: 91.79 %\n",
      "(32/60) epoch end, loss: 0.003437, Test Acc: 91.72 %\n",
      "(33/60) epoch end, loss: 0.003436, Test Acc: 91.79 %\n",
      "(34/60) epoch end, loss: 0.003434, Test Acc: 91.73 %\n",
      "(35/60) epoch end, loss: 0.003435, Test Acc: 91.81 %\n",
      "(36/60) epoch end, loss: 0.003431, Test Acc: 91.76 %\n",
      "(37/60) epoch end, loss: 0.003434, Test Acc: 91.73 %\n",
      "(38/60) epoch end, loss: 0.003430, Test Acc: 91.76 %\n",
      "(39/60) epoch end, loss: 0.003430, Test Acc: 91.63 %\n",
      "(40/60) epoch end, loss: 0.003431, Test Acc: 91.72 %\n",
      "(41/60) epoch end, loss: 0.003426, Test Acc: 91.72 %\n",
      "(42/60) epoch end, loss: 0.003424, Test Acc: 91.74 %\n",
      "(43/60) epoch end, loss: 0.003425, Test Acc: 91.64 %\n",
      "(44/60) epoch end, loss: 0.003422, Test Acc: 91.70 %\n",
      "(45/60) epoch end, loss: 0.003423, Test Acc: 91.84 %\n",
      "(46/60) epoch end, loss: 0.003424, Test Acc: 91.76 %\n",
      "(47/60) epoch end, loss: 0.003424, Test Acc: 91.76 %\n",
      "(48/60) epoch end, loss: 0.003421, Test Acc: 91.72 %\n",
      "(49/60) epoch end, loss: 0.003423, Test Acc: 91.75 %\n",
      "(50/60) epoch end, loss: 0.003424, Test Acc: 91.65 %\n",
      "(51/60) epoch end, loss: 0.003420, Test Acc: 91.73 %\n",
      "(52/60) epoch end, loss: 0.003422, Test Acc: 91.79 %\n",
      "(53/60) epoch end, loss: 0.003422, Test Acc: 91.65 %\n",
      "(54/60) epoch end, loss: 0.003424, Test Acc: 91.68 %\n",
      "(55/60) epoch end, loss: 0.003422, Test Acc: 91.73 %\n",
      "(56/60) epoch end, loss: 0.003421, Test Acc: 91.72 %\n",
      "(57/60) epoch end, loss: 0.003422, Test Acc: 91.75 %\n",
      "(58/60) epoch end, loss: 0.003421, Test Acc: 91.67 %\n",
      "(59/60) epoch end, loss: 0.003420, Test Acc: 91.56 %\n",
      "(60/60) epoch end, loss: 0.003420, Test Acc: 91.69 %\n",
      "\n",
      "Block 4 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.011510, Test Acc: 77.47 %\n",
      "(2/60) epoch end, loss: 0.005939, Test Acc: 86.77 %\n",
      "(3/60) epoch end, loss: 0.004995, Test Acc: 88.46 %\n",
      "(4/60) epoch end, loss: 0.004567, Test Acc: 89.14 %\n",
      "(5/60) epoch end, loss: 0.004397, Test Acc: 89.09 %\n",
      "(6/60) epoch end, loss: 0.004277, Test Acc: 89.49 %\n",
      "(7/60) epoch end, loss: 0.004126, Test Acc: 89.55 %\n",
      "(8/60) epoch end, loss: 0.004086, Test Acc: 89.38 %\n",
      "(9/60) epoch end, loss: 0.003968, Test Acc: 89.17 %\n",
      "(10/60) epoch end, loss: 0.003920, Test Acc: 89.80 %\n",
      "(11/60) epoch end, loss: 0.003881, Test Acc: 89.61 %\n",
      "(12/60) epoch end, loss: 0.003834, Test Acc: 89.40 %\n",
      "(13/60) epoch end, loss: 0.003828, Test Acc: 90.40 %\n",
      "(14/60) epoch end, loss: 0.003778, Test Acc: 90.37 %\n",
      "(15/60) epoch end, loss: 0.003746, Test Acc: 89.20 %\n",
      "(16/60) epoch end, loss: 0.003726, Test Acc: 89.92 %\n",
      "(17/60) epoch end, loss: 0.003705, Test Acc: 90.17 %\n",
      "(18/60) epoch end, loss: 0.003692, Test Acc: 89.79 %\n",
      "(19/60) epoch end, loss: 0.003668, Test Acc: 89.90 %\n",
      "(20/60) epoch end, loss: 0.003647, Test Acc: 89.86 %\n",
      "(21/60) epoch end, loss: 0.003579, Test Acc: 90.36 %\n",
      "(22/60) epoch end, loss: 0.003571, Test Acc: 90.42 %\n",
      "(23/60) epoch end, loss: 0.003567, Test Acc: 90.40 %\n",
      "(24/60) epoch end, loss: 0.003564, Test Acc: 90.37 %\n",
      "(25/60) epoch end, loss: 0.003567, Test Acc: 90.22 %\n",
      "(26/60) epoch end, loss: 0.003559, Test Acc: 90.36 %\n",
      "(27/60) epoch end, loss: 0.003559, Test Acc: 90.21 %\n",
      "(28/60) epoch end, loss: 0.003558, Test Acc: 90.24 %\n",
      "(29/60) epoch end, loss: 0.003556, Test Acc: 90.20 %\n",
      "(30/60) epoch end, loss: 0.003552, Test Acc: 90.28 %\n",
      "(31/60) epoch end, loss: 0.003550, Test Acc: 90.25 %\n",
      "(32/60) epoch end, loss: 0.003547, Test Acc: 90.34 %\n",
      "(33/60) epoch end, loss: 0.003545, Test Acc: 90.48 %\n",
      "(34/60) epoch end, loss: 0.003542, Test Acc: 90.30 %\n",
      "(35/60) epoch end, loss: 0.003537, Test Acc: 90.28 %\n",
      "(36/60) epoch end, loss: 0.003538, Test Acc: 90.41 %\n",
      "(37/60) epoch end, loss: 0.003533, Test Acc: 90.35 %\n",
      "(38/60) epoch end, loss: 0.003531, Test Acc: 90.27 %\n",
      "(39/60) epoch end, loss: 0.003529, Test Acc: 90.30 %\n",
      "(40/60) epoch end, loss: 0.003526, Test Acc: 90.15 %\n",
      "(41/60) epoch end, loss: 0.003520, Test Acc: 90.37 %\n",
      "(42/60) epoch end, loss: 0.003519, Test Acc: 90.42 %\n",
      "(43/60) epoch end, loss: 0.003519, Test Acc: 90.31 %\n",
      "(44/60) epoch end, loss: 0.003518, Test Acc: 90.45 %\n",
      "(45/60) epoch end, loss: 0.003517, Test Acc: 90.26 %\n",
      "(46/60) epoch end, loss: 0.003517, Test Acc: 90.40 %\n",
      "(47/60) epoch end, loss: 0.003517, Test Acc: 90.45 %\n",
      "(48/60) epoch end, loss: 0.003517, Test Acc: 90.37 %\n",
      "(49/60) epoch end, loss: 0.003518, Test Acc: 90.29 %\n",
      "(50/60) epoch end, loss: 0.003515, Test Acc: 90.39 %\n",
      "(51/60) epoch end, loss: 0.003515, Test Acc: 90.51 %\n",
      "(52/60) epoch end, loss: 0.003513, Test Acc: 90.19 %\n",
      "(53/60) epoch end, loss: 0.003515, Test Acc: 90.32 %\n",
      "(54/60) epoch end, loss: 0.003514, Test Acc: 90.29 %\n",
      "(55/60) epoch end, loss: 0.003515, Test Acc: 90.40 %\n",
      "(56/60) epoch end, loss: 0.003514, Test Acc: 90.40 %\n",
      "(57/60) epoch end, loss: 0.003515, Test Acc: 90.43 %\n",
      "(58/60) epoch end, loss: 0.003513, Test Acc: 90.26 %\n",
      "(59/60) epoch end, loss: 0.003511, Test Acc: 90.29 %\n",
      "(60/60) epoch end, loss: 0.003515, Test Acc: 90.32 %\n",
      "\n",
      "Block 5 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.005921, Test Acc: 85.54 %\n",
      "(2/60) epoch end, loss: 0.002982, Test Acc: 87.53 %\n",
      "(3/60) epoch end, loss: 0.002678, Test Acc: 88.12 %\n",
      "(4/60) epoch end, loss: 0.002539, Test Acc: 88.68 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5/60) epoch end, loss: 0.002483, Test Acc: 89.62 %\n",
      "(6/60) epoch end, loss: 0.002405, Test Acc: 89.36 %\n",
      "(7/60) epoch end, loss: 0.002357, Test Acc: 89.55 %\n",
      "(8/60) epoch end, loss: 0.002330, Test Acc: 89.87 %\n",
      "(9/60) epoch end, loss: 0.002303, Test Acc: 89.73 %\n",
      "(10/60) epoch end, loss: 0.002274, Test Acc: 90.05 %\n",
      "(11/60) epoch end, loss: 0.002252, Test Acc: 89.91 %\n",
      "(12/60) epoch end, loss: 0.002237, Test Acc: 90.10 %\n",
      "(13/60) epoch end, loss: 0.002217, Test Acc: 89.77 %\n",
      "(14/60) epoch end, loss: 0.002228, Test Acc: 89.96 %\n",
      "(15/60) epoch end, loss: 0.002189, Test Acc: 89.87 %\n",
      "(16/60) epoch end, loss: 0.002171, Test Acc: 90.17 %\n",
      "(17/60) epoch end, loss: 0.002164, Test Acc: 90.09 %\n",
      "(18/60) epoch end, loss: 0.002160, Test Acc: 90.40 %\n",
      "(19/60) epoch end, loss: 0.002140, Test Acc: 89.59 %\n",
      "(20/60) epoch end, loss: 0.002131, Test Acc: 90.51 %\n",
      "(21/60) epoch end, loss: 0.002076, Test Acc: 90.79 %\n",
      "(22/60) epoch end, loss: 0.002070, Test Acc: 90.81 %\n",
      "(23/60) epoch end, loss: 0.002063, Test Acc: 90.75 %\n",
      "(24/60) epoch end, loss: 0.002070, Test Acc: 90.80 %\n",
      "(25/60) epoch end, loss: 0.002066, Test Acc: 90.72 %\n",
      "(26/60) epoch end, loss: 0.002061, Test Acc: 90.90 %\n",
      "(27/60) epoch end, loss: 0.002059, Test Acc: 90.73 %\n",
      "(28/60) epoch end, loss: 0.002057, Test Acc: 90.88 %\n",
      "(29/60) epoch end, loss: 0.002057, Test Acc: 90.77 %\n",
      "(30/60) epoch end, loss: 0.002054, Test Acc: 90.75 %\n",
      "(31/60) epoch end, loss: 0.002055, Test Acc: 90.83 %\n",
      "(32/60) epoch end, loss: 0.002053, Test Acc: 90.83 %\n",
      "(33/60) epoch end, loss: 0.002068, Test Acc: 90.83 %\n",
      "(34/60) epoch end, loss: 0.002050, Test Acc: 90.78 %\n",
      "(35/60) epoch end, loss: 0.002050, Test Acc: 90.73 %\n",
      "(36/60) epoch end, loss: 0.002080, Test Acc: 90.68 %\n",
      "(37/60) epoch end, loss: 0.002052, Test Acc: 90.72 %\n",
      "(38/60) epoch end, loss: 0.002048, Test Acc: 90.75 %\n",
      "(39/60) epoch end, loss: 0.002047, Test Acc: 90.86 %\n",
      "(40/60) epoch end, loss: 0.002043, Test Acc: 90.71 %\n",
      "(41/60) epoch end, loss: 0.002040, Test Acc: 90.80 %\n",
      "(42/60) epoch end, loss: 0.002041, Test Acc: 90.82 %\n",
      "(43/60) epoch end, loss: 0.002039, Test Acc: 90.87 %\n",
      "(44/60) epoch end, loss: 0.002039, Test Acc: 90.96 %\n",
      "(45/60) epoch end, loss: 0.002040, Test Acc: 90.85 %\n",
      "(46/60) epoch end, loss: 0.002041, Test Acc: 90.83 %\n",
      "(47/60) epoch end, loss: 0.002039, Test Acc: 90.82 %\n",
      "(48/60) epoch end, loss: 0.002039, Test Acc: 90.73 %\n",
      "(49/60) epoch end, loss: 0.002059, Test Acc: 90.83 %\n",
      "(50/60) epoch end, loss: 0.002038, Test Acc: 90.85 %\n",
      "(51/60) epoch end, loss: 0.002038, Test Acc: 90.86 %\n",
      "(52/60) epoch end, loss: 0.002057, Test Acc: 90.75 %\n",
      "(53/60) epoch end, loss: 0.002036, Test Acc: 90.79 %\n",
      "(54/60) epoch end, loss: 0.002056, Test Acc: 90.84 %\n",
      "(55/60) epoch end, loss: 0.002037, Test Acc: 90.87 %\n",
      "(56/60) epoch end, loss: 0.002037, Test Acc: 90.91 %\n",
      "(57/60) epoch end, loss: 0.002036, Test Acc: 90.88 %\n",
      "(58/60) epoch end, loss: 0.002037, Test Acc: 90.83 %\n",
      "(59/60) epoch end, loss: 0.002038, Test Acc: 90.83 %\n",
      "(60/60) epoch end, loss: 0.002050, Test Acc: 90.79 %\n",
      "\n",
      "Block 6 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.003188, Test Acc: 87.68 %\n",
      "(2/60) epoch end, loss: 0.001268, Test Acc: 89.32 %\n",
      "(3/60) epoch end, loss: 0.001386, Test Acc: 88.64 %\n",
      "(4/60) epoch end, loss: 0.001338, Test Acc: 87.80 %\n",
      "(5/60) epoch end, loss: 0.001191, Test Acc: 88.40 %\n",
      "(6/60) epoch end, loss: 0.001092, Test Acc: 89.72 %\n",
      "(7/60) epoch end, loss: 0.001061, Test Acc: 89.46 %\n",
      "(8/60) epoch end, loss: 0.001043, Test Acc: 89.95 %\n",
      "(9/60) epoch end, loss: 0.000991, Test Acc: 89.82 %\n",
      "(10/60) epoch end, loss: 0.000972, Test Acc: 90.21 %\n",
      "(11/60) epoch end, loss: 0.000952, Test Acc: 90.48 %\n",
      "(12/60) epoch end, loss: 0.001054, Test Acc: 89.52 %\n",
      "(13/60) epoch end, loss: 0.001002, Test Acc: 89.89 %\n",
      "(14/60) epoch end, loss: 0.000945, Test Acc: 89.98 %\n",
      "(15/60) epoch end, loss: 0.000922, Test Acc: 90.64 %\n",
      "(16/60) epoch end, loss: 0.000908, Test Acc: 90.41 %\n",
      "(17/60) epoch end, loss: 0.000906, Test Acc: 90.67 %\n",
      "(18/60) epoch end, loss: 0.000889, Test Acc: 90.31 %\n",
      "(19/60) epoch end, loss: 0.001029, Test Acc: 89.22 %\n",
      "(20/60) epoch end, loss: 0.000976, Test Acc: 89.71 %\n",
      "(21/60) epoch end, loss: 0.000908, Test Acc: 90.72 %\n",
      "(22/60) epoch end, loss: 0.000896, Test Acc: 90.70 %\n",
      "(23/60) epoch end, loss: 0.000888, Test Acc: 90.97 %\n",
      "(24/60) epoch end, loss: 0.000880, Test Acc: 90.79 %\n",
      "(25/60) epoch end, loss: 0.000874, Test Acc: 91.13 %\n",
      "(26/60) epoch end, loss: 0.000864, Test Acc: 91.08 %\n",
      "(27/60) epoch end, loss: 0.000860, Test Acc: 90.98 %\n",
      "(28/60) epoch end, loss: 0.000850, Test Acc: 91.16 %\n",
      "(29/60) epoch end, loss: 0.000843, Test Acc: 91.14 %\n",
      "(30/60) epoch end, loss: 0.000839, Test Acc: 91.08 %\n",
      "(31/60) epoch end, loss: 0.000833, Test Acc: 91.23 %\n",
      "(32/60) epoch end, loss: 0.000829, Test Acc: 91.12 %\n",
      "(33/60) epoch end, loss: 0.000824, Test Acc: 91.22 %\n",
      "(34/60) epoch end, loss: 0.000824, Test Acc: 91.26 %\n",
      "(35/60) epoch end, loss: 0.000819, Test Acc: 91.32 %\n",
      "(36/60) epoch end, loss: 0.000822, Test Acc: 91.42 %\n",
      "(37/60) epoch end, loss: 0.000815, Test Acc: 91.41 %\n",
      "(38/60) epoch end, loss: 0.000812, Test Acc: 91.42 %\n",
      "(39/60) epoch end, loss: 0.000811, Test Acc: 91.36 %\n",
      "(40/60) epoch end, loss: 0.000809, Test Acc: 91.47 %\n",
      "(41/60) epoch end, loss: 0.000805, Test Acc: 91.57 %\n",
      "(42/60) epoch end, loss: 0.000802, Test Acc: 91.52 %\n",
      "(43/60) epoch end, loss: 0.000807, Test Acc: 91.47 %\n",
      "(44/60) epoch end, loss: 0.000821, Test Acc: 91.48 %\n",
      "(45/60) epoch end, loss: 0.000802, Test Acc: 91.45 %\n",
      "(46/60) epoch end, loss: 0.000816, Test Acc: 91.29 %\n",
      "(47/60) epoch end, loss: 0.000803, Test Acc: 91.54 %\n",
      "(48/60) epoch end, loss: 0.000802, Test Acc: 91.41 %\n",
      "(49/60) epoch end, loss: 0.000801, Test Acc: 91.42 %\n",
      "(50/60) epoch end, loss: 0.000801, Test Acc: 91.47 %\n",
      "(51/60) epoch end, loss: 0.000802, Test Acc: 91.51 %\n",
      "(52/60) epoch end, loss: 0.000799, Test Acc: 91.59 %\n",
      "(53/60) epoch end, loss: 0.000800, Test Acc: 91.48 %\n",
      "(54/60) epoch end, loss: 0.000800, Test Acc: 91.53 %\n",
      "(55/60) epoch end, loss: 0.000800, Test Acc: 91.55 %\n",
      "(56/60) epoch end, loss: 0.000801, Test Acc: 91.41 %\n",
      "(57/60) epoch end, loss: 0.000801, Test Acc: 91.56 %\n",
      "(58/60) epoch end, loss: 0.000799, Test Acc: 91.47 %\n",
      "(59/60) epoch end, loss: 0.000800, Test Acc: 91.54 %\n",
      "(60/60) epoch end, loss: 0.000800, Test Acc: 91.40 %\n",
      "\n",
      "Block 7 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.001426, Test Acc: 90.27 %\n",
      "(2/60) epoch end, loss: 0.000606, Test Acc: 89.03 %\n",
      "(3/60) epoch end, loss: 0.000503, Test Acc: 89.72 %\n",
      "(4/60) epoch end, loss: 0.000456, Test Acc: 89.94 %\n",
      "(5/60) epoch end, loss: 0.000435, Test Acc: 90.32 %\n",
      "(6/60) epoch end, loss: 0.000423, Test Acc: 90.68 %\n",
      "(7/60) epoch end, loss: 0.000421, Test Acc: 90.22 %\n",
      "(8/60) epoch end, loss: 0.000423, Test Acc: 90.32 %\n",
      "(9/60) epoch end, loss: 0.000414, Test Acc: 89.45 %\n",
      "(10/60) epoch end, loss: 0.000410, Test Acc: 90.19 %\n",
      "(11/60) epoch end, loss: 0.000388, Test Acc: 90.88 %\n",
      "(12/60) epoch end, loss: 0.000380, Test Acc: 90.68 %\n",
      "(13/60) epoch end, loss: 0.000385, Test Acc: 91.05 %\n",
      "(14/60) epoch end, loss: 0.000401, Test Acc: 90.51 %\n",
      "(15/60) epoch end, loss: 0.000376, Test Acc: 90.74 %\n",
      "(16/60) epoch end, loss: 0.000366, Test Acc: 90.89 %\n",
      "(17/60) epoch end, loss: 0.000366, Test Acc: 90.75 %\n",
      "(18/60) epoch end, loss: 0.000378, Test Acc: 90.64 %\n",
      "(19/60) epoch end, loss: 0.000359, Test Acc: 90.36 %\n",
      "(20/60) epoch end, loss: 0.000354, Test Acc: 90.77 %\n",
      "(21/60) epoch end, loss: 0.000323, Test Acc: 91.45 %\n",
      "(22/60) epoch end, loss: 0.000316, Test Acc: 91.39 %\n",
      "(23/60) epoch end, loss: 0.000312, Test Acc: 91.57 %\n",
      "(24/60) epoch end, loss: 0.000310, Test Acc: 91.51 %\n",
      "(25/60) epoch end, loss: 0.000309, Test Acc: 91.61 %\n",
      "(26/60) epoch end, loss: 0.000306, Test Acc: 91.66 %\n",
      "(27/60) epoch end, loss: 0.000307, Test Acc: 91.61 %\n",
      "(28/60) epoch end, loss: 0.000305, Test Acc: 91.78 %\n",
      "(29/60) epoch end, loss: 0.000304, Test Acc: 91.83 %\n",
      "(30/60) epoch end, loss: 0.000310, Test Acc: 91.66 %\n",
      "(31/60) epoch end, loss: 0.000305, Test Acc: 91.78 %\n",
      "(32/60) epoch end, loss: 0.000300, Test Acc: 91.63 %\n",
      "(33/60) epoch end, loss: 0.000302, Test Acc: 91.76 %\n",
      "(34/60) epoch end, loss: 0.000303, Test Acc: 91.66 %\n",
      "(35/60) epoch end, loss: 0.000301, Test Acc: 91.73 %\n",
      "(36/60) epoch end, loss: 0.000301, Test Acc: 91.74 %\n",
      "(37/60) epoch end, loss: 0.000299, Test Acc: 91.67 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38/60) epoch end, loss: 0.000298, Test Acc: 91.75 %\n",
      "(39/60) epoch end, loss: 0.000299, Test Acc: 91.92 %\n",
      "(40/60) epoch end, loss: 0.000297, Test Acc: 91.76 %\n",
      "(41/60) epoch end, loss: 0.000294, Test Acc: 91.89 %\n",
      "(42/60) epoch end, loss: 0.000294, Test Acc: 91.68 %\n",
      "(43/60) epoch end, loss: 0.000292, Test Acc: 91.74 %\n",
      "(44/60) epoch end, loss: 0.000293, Test Acc: 91.79 %\n",
      "(45/60) epoch end, loss: 0.000294, Test Acc: 91.90 %\n",
      "(46/60) epoch end, loss: 0.000294, Test Acc: 91.72 %\n",
      "(47/60) epoch end, loss: 0.000294, Test Acc: 91.81 %\n",
      "(48/60) epoch end, loss: 0.000293, Test Acc: 91.61 %\n",
      "(49/60) epoch end, loss: 0.000294, Test Acc: 91.91 %\n",
      "(50/60) epoch end, loss: 0.000294, Test Acc: 91.80 %\n",
      "(51/60) epoch end, loss: 0.000291, Test Acc: 91.90 %\n",
      "(52/60) epoch end, loss: 0.000292, Test Acc: 91.83 %\n",
      "(53/60) epoch end, loss: 0.000292, Test Acc: 91.87 %\n",
      "(54/60) epoch end, loss: 0.000291, Test Acc: 91.74 %\n",
      "(55/60) epoch end, loss: 0.000292, Test Acc: 91.84 %\n",
      "(56/60) epoch end, loss: 0.000292, Test Acc: 91.74 %\n",
      "(57/60) epoch end, loss: 0.000293, Test Acc: 91.80 %\n",
      "(58/60) epoch end, loss: 0.000292, Test Acc: 91.83 %\n",
      "(59/60) epoch end, loss: 0.000291, Test Acc: 91.88 %\n",
      "(60/60) epoch end, loss: 0.000292, Test Acc: 91.83 %\n",
      "\n",
      "Block 8 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.000799, Test Acc: 91.22 %\n",
      "(2/60) epoch end, loss: 0.000236, Test Acc: 90.68 %\n",
      "(3/60) epoch end, loss: 0.000250, Test Acc: 90.33 %\n",
      "(4/60) epoch end, loss: 0.000181, Test Acc: 91.02 %\n",
      "(5/60) epoch end, loss: 0.000166, Test Acc: 91.13 %\n",
      "(6/60) epoch end, loss: 0.000160, Test Acc: 90.79 %\n",
      "(7/60) epoch end, loss: 0.000272, Test Acc: 89.38 %\n",
      "(8/60) epoch end, loss: 0.000177, Test Acc: 90.82 %\n",
      "(9/60) epoch end, loss: 0.000157, Test Acc: 90.80 %\n",
      "(10/60) epoch end, loss: 0.000151, Test Acc: 91.30 %\n",
      "(11/60) epoch end, loss: 0.000147, Test Acc: 91.39 %\n",
      "(12/60) epoch end, loss: 0.000145, Test Acc: 90.43 %\n",
      "(13/60) epoch end, loss: 0.000156, Test Acc: 90.73 %\n",
      "(14/60) epoch end, loss: 0.000145, Test Acc: 90.94 %\n",
      "(15/60) epoch end, loss: 0.000139, Test Acc: 90.95 %\n",
      "(16/60) epoch end, loss: 0.000139, Test Acc: 91.10 %\n",
      "(17/60) epoch end, loss: 0.000131, Test Acc: 90.70 %\n",
      "(18/60) epoch end, loss: 0.000161, Test Acc: 90.75 %\n",
      "(19/60) epoch end, loss: 0.000134, Test Acc: 90.78 %\n",
      "(20/60) epoch end, loss: 0.000130, Test Acc: 90.99 %\n",
      "(21/60) epoch end, loss: 0.000116, Test Acc: 91.80 %\n",
      "(22/60) epoch end, loss: 0.000112, Test Acc: 91.86 %\n",
      "(23/60) epoch end, loss: 0.000111, Test Acc: 91.65 %\n",
      "(24/60) epoch end, loss: 0.000109, Test Acc: 91.87 %\n",
      "(25/60) epoch end, loss: 0.000107, Test Acc: 92.01 %\n",
      "(26/60) epoch end, loss: 0.000106, Test Acc: 91.87 %\n",
      "(27/60) epoch end, loss: 0.000106, Test Acc: 91.89 %\n",
      "(28/60) epoch end, loss: 0.000105, Test Acc: 91.86 %\n",
      "(29/60) epoch end, loss: 0.000105, Test Acc: 91.90 %\n",
      "(30/60) epoch end, loss: 0.000105, Test Acc: 91.93 %\n",
      "(31/60) epoch end, loss: 0.000103, Test Acc: 91.83 %\n",
      "(32/60) epoch end, loss: 0.000103, Test Acc: 91.81 %\n",
      "(33/60) epoch end, loss: 0.000103, Test Acc: 91.92 %\n",
      "(34/60) epoch end, loss: 0.000102, Test Acc: 91.80 %\n",
      "(35/60) epoch end, loss: 0.000103, Test Acc: 91.84 %\n",
      "(36/60) epoch end, loss: 0.000102, Test Acc: 91.88 %\n",
      "(37/60) epoch end, loss: 0.000101, Test Acc: 91.87 %\n",
      "(38/60) epoch end, loss: 0.000102, Test Acc: 91.92 %\n",
      "(39/60) epoch end, loss: 0.000101, Test Acc: 92.06 %\n",
      "(40/60) epoch end, loss: 0.000101, Test Acc: 91.88 %\n",
      "(41/60) epoch end, loss: 0.000099, Test Acc: 91.98 %\n",
      "(42/60) epoch end, loss: 0.000099, Test Acc: 92.00 %\n",
      "(43/60) epoch end, loss: 0.000099, Test Acc: 92.00 %\n",
      "(44/60) epoch end, loss: 0.000099, Test Acc: 92.06 %\n",
      "(45/60) epoch end, loss: 0.000098, Test Acc: 92.21 %\n",
      "(46/60) epoch end, loss: 0.000099, Test Acc: 91.97 %\n",
      "(47/60) epoch end, loss: 0.000099, Test Acc: 92.01 %\n",
      "(48/60) epoch end, loss: 0.000099, Test Acc: 91.97 %\n",
      "(49/60) epoch end, loss: 0.000099, Test Acc: 91.98 %\n",
      "(50/60) epoch end, loss: 0.000098, Test Acc: 92.07 %\n",
      "(51/60) epoch end, loss: 0.000099, Test Acc: 91.99 %\n",
      "(52/60) epoch end, loss: 0.000099, Test Acc: 92.00 %\n",
      "(53/60) epoch end, loss: 0.000099, Test Acc: 92.00 %\n",
      "(54/60) epoch end, loss: 0.000099, Test Acc: 91.96 %\n",
      "(55/60) epoch end, loss: 0.000098, Test Acc: 92.05 %\n",
      "(56/60) epoch end, loss: 0.000099, Test Acc: 92.00 %\n",
      "(57/60) epoch end, loss: 0.000098, Test Acc: 91.95 %\n",
      "(58/60) epoch end, loss: 0.000099, Test Acc: 91.99 %\n",
      "(59/60) epoch end, loss: 0.000099, Test Acc: 92.04 %\n",
      "(60/60) epoch end, loss: 0.000098, Test Acc: 92.01 %\n",
      "\n",
      "Block 9 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.000864, Test Acc: 88.73 %\n",
      "(2/60) epoch end, loss: 0.000612, Test Acc: 86.31 %\n",
      "(3/60) epoch end, loss: 0.000260, Test Acc: 87.60 %\n",
      "(4/60) epoch end, loss: 0.000200, Test Acc: 90.30 %\n",
      "(5/60) epoch end, loss: 0.000184, Test Acc: 68.59 %\n",
      "(6/60) epoch end, loss: 0.000293, Test Acc: 88.43 %\n",
      "(7/60) epoch end, loss: 0.000184, Test Acc: 90.08 %\n",
      "(8/60) epoch end, loss: 0.000156, Test Acc: 90.13 %\n",
      "(9/60) epoch end, loss: 0.000143, Test Acc: 90.62 %\n",
      "(10/60) epoch end, loss: 0.000132, Test Acc: 90.95 %\n",
      "(11/60) epoch end, loss: 0.000128, Test Acc: 90.98 %\n",
      "(12/60) epoch end, loss: 0.000123, Test Acc: 90.47 %\n",
      "(13/60) epoch end, loss: 0.000127, Test Acc: 89.82 %\n",
      "(14/60) epoch end, loss: 0.000142, Test Acc: 90.28 %\n",
      "(15/60) epoch end, loss: 0.000124, Test Acc: 90.77 %\n",
      "(16/60) epoch end, loss: 0.000171, Test Acc: 87.22 %\n",
      "(17/60) epoch end, loss: 0.000314, Test Acc: 86.02 %\n",
      "(18/60) epoch end, loss: 0.000184, Test Acc: 87.70 %\n",
      "(19/60) epoch end, loss: 0.000153, Test Acc: 87.91 %\n",
      "(20/60) epoch end, loss: 0.000165, Test Acc: 88.73 %\n",
      "(21/60) epoch end, loss: 0.000125, Test Acc: 89.55 %\n",
      "(22/60) epoch end, loss: 0.000119, Test Acc: 89.65 %\n",
      "(23/60) epoch end, loss: 0.000117, Test Acc: 89.79 %\n",
      "(24/60) epoch end, loss: 0.000110, Test Acc: 90.03 %\n",
      "(25/60) epoch end, loss: 0.000109, Test Acc: 90.05 %\n",
      "(26/60) epoch end, loss: 0.000106, Test Acc: 90.30 %\n",
      "(27/60) epoch end, loss: 0.000102, Test Acc: 90.79 %\n",
      "(28/60) epoch end, loss: 0.000100, Test Acc: 90.68 %\n",
      "(29/60) epoch end, loss: 0.000096, Test Acc: 91.02 %\n",
      "(30/60) epoch end, loss: 0.000093, Test Acc: 90.70 %\n",
      "(31/60) epoch end, loss: 0.000091, Test Acc: 91.09 %\n",
      "(32/60) epoch end, loss: 0.000089, Test Acc: 90.79 %\n",
      "(33/60) epoch end, loss: 0.000088, Test Acc: 91.27 %\n",
      "(34/60) epoch end, loss: 0.000086, Test Acc: 91.07 %\n",
      "(35/60) epoch end, loss: 0.000084, Test Acc: 90.98 %\n",
      "(36/60) epoch end, loss: 0.000083, Test Acc: 90.80 %\n",
      "(37/60) epoch end, loss: 0.000088, Test Acc: 90.67 %\n",
      "(38/60) epoch end, loss: 0.000089, Test Acc: 90.78 %\n",
      "(39/60) epoch end, loss: 0.000086, Test Acc: 90.87 %\n",
      "(40/60) epoch end, loss: 0.000082, Test Acc: 91.04 %\n",
      "(41/60) epoch end, loss: 0.000080, Test Acc: 91.29 %\n",
      "(42/60) epoch end, loss: 0.000081, Test Acc: 91.14 %\n",
      "(43/60) epoch end, loss: 0.000079, Test Acc: 91.25 %\n",
      "(44/60) epoch end, loss: 0.000079, Test Acc: 91.19 %\n",
      "(45/60) epoch end, loss: 0.000079, Test Acc: 91.42 %\n",
      "(46/60) epoch end, loss: 0.000078, Test Acc: 90.92 %\n",
      "(47/60) epoch end, loss: 0.000079, Test Acc: 91.08 %\n",
      "(48/60) epoch end, loss: 0.000078, Test Acc: 91.31 %\n",
      "(49/60) epoch end, loss: 0.000078, Test Acc: 91.28 %\n",
      "(50/60) epoch end, loss: 0.000078, Test Acc: 91.32 %\n",
      "(51/60) epoch end, loss: 0.000078, Test Acc: 91.44 %\n",
      "(52/60) epoch end, loss: 0.000077, Test Acc: 91.28 %\n",
      "(53/60) epoch end, loss: 0.000077, Test Acc: 91.29 %\n",
      "(54/60) epoch end, loss: 0.000078, Test Acc: 91.07 %\n",
      "(55/60) epoch end, loss: 0.000076, Test Acc: 91.24 %\n",
      "(56/60) epoch end, loss: 0.000077, Test Acc: 90.70 %\n",
      "(57/60) epoch end, loss: 0.000080, Test Acc: 91.32 %\n",
      "(58/60) epoch end, loss: 0.000076, Test Acc: 91.38 %\n",
      "(59/60) epoch end, loss: 0.000077, Test Acc: 91.36 %\n",
      "(60/60) epoch end, loss: 0.000076, Test Acc: 91.36 %\n",
      "\n",
      "Block 10 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.000689, Test Acc: 87.90 %\n",
      "(2/60) epoch end, loss: 0.000122, Test Acc: 87.70 %\n",
      "(3/60) epoch end, loss: 0.000162, Test Acc: 88.38 %\n",
      "(4/60) epoch end, loss: 0.000105, Test Acc: 87.69 %\n",
      "(5/60) epoch end, loss: 0.000252, Test Acc: 84.08 %\n",
      "(6/60) epoch end, loss: 0.000132, Test Acc: 87.09 %\n",
      "(7/60) epoch end, loss: 0.000100, Test Acc: 88.18 %\n",
      "(8/60) epoch end, loss: 0.000106, Test Acc: 89.09 %\n",
      "(9/60) epoch end, loss: 0.000076, Test Acc: 90.12 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10/60) epoch end, loss: 0.000073, Test Acc: 89.45 %\n",
      "(11/60) epoch end, loss: 0.000079, Test Acc: 89.10 %\n",
      "(12/60) epoch end, loss: 0.000066, Test Acc: 90.12 %\n",
      "(13/60) epoch end, loss: 0.000059, Test Acc: 89.78 %\n",
      "(14/60) epoch end, loss: 0.000060, Test Acc: 88.58 %\n",
      "(15/60) epoch end, loss: 0.000123, Test Acc: 89.19 %\n",
      "(16/60) epoch end, loss: 0.000066, Test Acc: 89.56 %\n",
      "(17/60) epoch end, loss: 0.000060, Test Acc: 89.18 %\n",
      "(18/60) epoch end, loss: 0.000055, Test Acc: 88.77 %\n",
      "(19/60) epoch end, loss: 0.000055, Test Acc: 78.83 %\n",
      "(20/60) epoch end, loss: 0.000069, Test Acc: 88.11 %\n",
      "(21/60) epoch end, loss: 0.000047, Test Acc: 91.15 %\n",
      "(22/60) epoch end, loss: 0.000042, Test Acc: 90.73 %\n",
      "(23/60) epoch end, loss: 0.000040, Test Acc: 91.41 %\n",
      "(24/60) epoch end, loss: 0.000039, Test Acc: 91.28 %\n",
      "(25/60) epoch end, loss: 0.000037, Test Acc: 91.05 %\n",
      "(26/60) epoch end, loss: 0.000039, Test Acc: 90.92 %\n",
      "(27/60) epoch end, loss: 0.000037, Test Acc: 91.39 %\n",
      "(28/60) epoch end, loss: 0.000036, Test Acc: 91.27 %\n",
      "(29/60) epoch end, loss: 0.000035, Test Acc: 91.64 %\n",
      "(30/60) epoch end, loss: 0.000034, Test Acc: 90.77 %\n",
      "(31/60) epoch end, loss: 0.000035, Test Acc: 91.25 %\n",
      "(32/60) epoch end, loss: 0.000034, Test Acc: 91.25 %\n",
      "(33/60) epoch end, loss: 0.000034, Test Acc: 91.38 %\n",
      "(34/60) epoch end, loss: 0.000033, Test Acc: 91.49 %\n",
      "(35/60) epoch end, loss: 0.000032, Test Acc: 90.62 %\n",
      "(36/60) epoch end, loss: 0.000033, Test Acc: 91.02 %\n",
      "(37/60) epoch end, loss: 0.000033, Test Acc: 91.13 %\n",
      "(38/60) epoch end, loss: 0.000032, Test Acc: 90.84 %\n",
      "(39/60) epoch end, loss: 0.000031, Test Acc: 91.08 %\n",
      "(40/60) epoch end, loss: 0.000032, Test Acc: 91.28 %\n",
      "(41/60) epoch end, loss: 0.000031, Test Acc: 91.17 %\n",
      "(42/60) epoch end, loss: 0.000031, Test Acc: 90.90 %\n",
      "(43/60) epoch end, loss: 0.000030, Test Acc: 91.33 %\n",
      "(44/60) epoch end, loss: 0.000030, Test Acc: 91.13 %\n",
      "(45/60) epoch end, loss: 0.000030, Test Acc: 91.27 %\n",
      "(46/60) epoch end, loss: 0.000030, Test Acc: 90.90 %\n",
      "(47/60) epoch end, loss: 0.000030, Test Acc: 91.06 %\n",
      "(48/60) epoch end, loss: 0.000030, Test Acc: 90.91 %\n",
      "(49/60) epoch end, loss: 0.000031, Test Acc: 90.84 %\n",
      "(50/60) epoch end, loss: 0.000030, Test Acc: 91.14 %\n",
      "(51/60) epoch end, loss: 0.000029, Test Acc: 91.10 %\n",
      "(52/60) epoch end, loss: 0.000030, Test Acc: 91.12 %\n",
      "(53/60) epoch end, loss: 0.000029, Test Acc: 91.14 %\n",
      "(54/60) epoch end, loss: 0.000030, Test Acc: 90.79 %\n",
      "(55/60) epoch end, loss: 0.000030, Test Acc: 91.10 %\n",
      "(56/60) epoch end, loss: 0.000030, Test Acc: 91.11 %\n",
      "(57/60) epoch end, loss: 0.000030, Test Acc: 91.29 %\n",
      "(58/60) epoch end, loss: 0.000030, Test Acc: 90.93 %\n",
      "(59/60) epoch end, loss: 0.000029, Test Acc: 91.26 %\n",
      "(60/60) epoch end, loss: 0.000030, Test Acc: 91.20 %\n",
      "\n",
      "Block 11 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.000733, Test Acc: 84.26 %\n",
      "(2/60) epoch end, loss: 0.000240, Test Acc: 82.12 %\n",
      "(3/60) epoch end, loss: 0.000170, Test Acc: 86.96 %\n",
      "(4/60) epoch end, loss: 0.000121, Test Acc: 88.33 %\n",
      "(5/60) epoch end, loss: 0.000099, Test Acc: 88.46 %\n",
      "(6/60) epoch end, loss: 0.000090, Test Acc: 88.77 %\n",
      "(7/60) epoch end, loss: 0.000083, Test Acc: 89.17 %\n",
      "(8/60) epoch end, loss: 0.000084, Test Acc: 89.16 %\n",
      "(9/60) epoch end, loss: 0.000079, Test Acc: 89.88 %\n",
      "(10/60) epoch end, loss: 0.000067, Test Acc: 90.09 %\n",
      "(11/60) epoch end, loss: 0.000073, Test Acc: 88.33 %\n",
      "(12/60) epoch end, loss: 0.000084, Test Acc: 89.04 %\n",
      "(13/60) epoch end, loss: 0.000083, Test Acc: 78.99 %\n",
      "(14/60) epoch end, loss: 0.000246, Test Acc: 84.82 %\n",
      "(15/60) epoch end, loss: 0.000128, Test Acc: 87.62 %\n",
      "(16/60) epoch end, loss: 0.000096, Test Acc: 89.13 %\n",
      "(17/60) epoch end, loss: 0.000082, Test Acc: 89.14 %\n",
      "(18/60) epoch end, loss: 0.000074, Test Acc: 88.40 %\n",
      "(19/60) epoch end, loss: 0.000080, Test Acc: 89.58 %\n",
      "(20/60) epoch end, loss: 0.000066, Test Acc: 89.22 %\n",
      "(21/60) epoch end, loss: 0.000054, Test Acc: 90.15 %\n",
      "(22/60) epoch end, loss: 0.000050, Test Acc: 90.39 %\n",
      "(23/60) epoch end, loss: 0.000048, Test Acc: 90.29 %\n",
      "(24/60) epoch end, loss: 0.000045, Test Acc: 90.14 %\n",
      "(25/60) epoch end, loss: 0.000045, Test Acc: 89.92 %\n",
      "(26/60) epoch end, loss: 0.000044, Test Acc: 90.68 %\n",
      "(27/60) epoch end, loss: 0.000043, Test Acc: 90.54 %\n",
      "(28/60) epoch end, loss: 0.000042, Test Acc: 90.66 %\n",
      "(29/60) epoch end, loss: 0.000041, Test Acc: 90.77 %\n",
      "(30/60) epoch end, loss: 0.000041, Test Acc: 90.08 %\n",
      "(31/60) epoch end, loss: 0.000040, Test Acc: 90.43 %\n",
      "(32/60) epoch end, loss: 0.000039, Test Acc: 90.04 %\n",
      "(33/60) epoch end, loss: 0.000039, Test Acc: 90.80 %\n",
      "(34/60) epoch end, loss: 0.000039, Test Acc: 90.21 %\n",
      "(35/60) epoch end, loss: 0.000038, Test Acc: 90.72 %\n",
      "(36/60) epoch end, loss: 0.000038, Test Acc: 90.87 %\n",
      "(37/60) epoch end, loss: 0.000037, Test Acc: 90.80 %\n",
      "(38/60) epoch end, loss: 0.000037, Test Acc: 90.61 %\n",
      "(39/60) epoch end, loss: 0.000036, Test Acc: 90.64 %\n",
      "(40/60) epoch end, loss: 0.000036, Test Acc: 90.60 %\n",
      "(41/60) epoch end, loss: 0.000035, Test Acc: 90.11 %\n",
      "(42/60) epoch end, loss: 0.000035, Test Acc: 90.31 %\n",
      "(43/60) epoch end, loss: 0.000034, Test Acc: 90.81 %\n",
      "(44/60) epoch end, loss: 0.000034, Test Acc: 90.42 %\n",
      "(45/60) epoch end, loss: 0.000034, Test Acc: 90.90 %\n",
      "(46/60) epoch end, loss: 0.000034, Test Acc: 90.61 %\n",
      "(47/60) epoch end, loss: 0.000034, Test Acc: 90.40 %\n",
      "(48/60) epoch end, loss: 0.000035, Test Acc: 90.78 %\n",
      "(49/60) epoch end, loss: 0.000034, Test Acc: 90.23 %\n",
      "(50/60) epoch end, loss: 0.000034, Test Acc: 90.99 %\n",
      "(51/60) epoch end, loss: 0.000034, Test Acc: 90.65 %\n",
      "(52/60) epoch end, loss: 0.000034, Test Acc: 90.66 %\n",
      "(53/60) epoch end, loss: 0.000034, Test Acc: 90.81 %\n",
      "(54/60) epoch end, loss: 0.000034, Test Acc: 90.81 %\n",
      "(55/60) epoch end, loss: 0.000034, Test Acc: 90.85 %\n",
      "(56/60) epoch end, loss: 0.000034, Test Acc: 90.55 %\n",
      "(57/60) epoch end, loss: 0.000035, Test Acc: 90.51 %\n",
      "(58/60) epoch end, loss: 0.000034, Test Acc: 90.73 %\n",
      "(59/60) epoch end, loss: 0.000034, Test Acc: 90.97 %\n",
      "(60/60) epoch end, loss: 0.000034, Test Acc: 90.89 %\n",
      "\n",
      "Block 12 recasting is done (ConvBlock -> ConvBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.009012, Test Acc: 88.78 %\n",
      "(2/60) epoch end, loss: 0.005024, Test Acc: 88.43 %\n",
      "(3/60) epoch end, loss: 0.005779, Test Acc: 88.27 %\n",
      "(4/60) epoch end, loss: 0.005983, Test Acc: 88.39 %\n",
      "(5/60) epoch end, loss: 0.005597, Test Acc: 88.04 %\n",
      "(6/60) epoch end, loss: 0.005565, Test Acc: 81.73 %\n",
      "(7/60) epoch end, loss: 0.006332, Test Acc: 87.01 %\n",
      "(8/60) epoch end, loss: 0.005454, Test Acc: 87.64 %\n",
      "(9/60) epoch end, loss: 0.005714, Test Acc: 87.97 %\n",
      "(10/60) epoch end, loss: 0.006049, Test Acc: 89.07 %\n",
      "(11/60) epoch end, loss: 0.006013, Test Acc: 84.92 %\n",
      "(12/60) epoch end, loss: 0.005524, Test Acc: 88.27 %\n",
      "(13/60) epoch end, loss: 0.005318, Test Acc: 88.82 %\n",
      "(14/60) epoch end, loss: 0.006239, Test Acc: 81.90 %\n",
      "(15/60) epoch end, loss: 0.006872, Test Acc: 87.42 %\n",
      "(16/60) epoch end, loss: 0.008677, Test Acc: 87.87 %\n",
      "(17/60) epoch end, loss: 0.006995, Test Acc: 87.72 %\n",
      "(18/60) epoch end, loss: 0.006383, Test Acc: 89.61 %\n",
      "(19/60) epoch end, loss: 0.005455, Test Acc: 89.71 %\n",
      "(20/60) epoch end, loss: 0.005898, Test Acc: 84.76 %\n",
      "(21/60) epoch end, loss: 0.006930, Test Acc: 88.46 %\n",
      "(22/60) epoch end, loss: 0.005713, Test Acc: 88.69 %\n",
      "(23/60) epoch end, loss: 0.005280, Test Acc: 88.70 %\n",
      "(24/60) epoch end, loss: 0.005058, Test Acc: 89.13 %\n",
      "(25/60) epoch end, loss: 0.004793, Test Acc: 89.83 %\n",
      "(26/60) epoch end, loss: 0.004707, Test Acc: 89.96 %\n",
      "(27/60) epoch end, loss: 0.004551, Test Acc: 89.98 %\n",
      "(28/60) epoch end, loss: 0.004467, Test Acc: 90.02 %\n",
      "(29/60) epoch end, loss: 0.004389, Test Acc: 89.97 %\n",
      "(30/60) epoch end, loss: 0.004311, Test Acc: 90.10 %\n",
      "(31/60) epoch end, loss: 0.004287, Test Acc: 90.52 %\n",
      "(32/60) epoch end, loss: 0.004298, Test Acc: 90.39 %\n",
      "(33/60) epoch end, loss: 0.004313, Test Acc: 90.03 %\n",
      "(34/60) epoch end, loss: 0.004276, Test Acc: 90.35 %\n",
      "(35/60) epoch end, loss: 0.004093, Test Acc: 90.06 %\n",
      "(36/60) epoch end, loss: 0.004153, Test Acc: 90.36 %\n",
      "(37/60) epoch end, loss: 0.004140, Test Acc: 89.28 %\n",
      "(38/60) epoch end, loss: 0.004076, Test Acc: 89.76 %\n",
      "(39/60) epoch end, loss: 0.003931, Test Acc: 90.26 %\n",
      "(40/60) epoch end, loss: 0.003995, Test Acc: 90.33 %\n",
      "(41/60) epoch end, loss: 0.003910, Test Acc: 90.11 %\n",
      "(42/60) epoch end, loss: 0.003901, Test Acc: 90.42 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43/60) epoch end, loss: 0.003856, Test Acc: 90.42 %\n",
      "(44/60) epoch end, loss: 0.003912, Test Acc: 90.17 %\n",
      "(45/60) epoch end, loss: 0.003879, Test Acc: 89.86 %\n",
      "(46/60) epoch end, loss: 0.003875, Test Acc: 90.29 %\n",
      "(47/60) epoch end, loss: 0.003773, Test Acc: 90.35 %\n",
      "(48/60) epoch end, loss: 0.003797, Test Acc: 90.45 %\n",
      "(49/60) epoch end, loss: 0.003759, Test Acc: 90.63 %\n",
      "(50/60) epoch end, loss: 0.003791, Test Acc: 90.61 %\n",
      "(51/60) epoch end, loss: 0.003752, Test Acc: 90.44 %\n",
      "(52/60) epoch end, loss: 0.003812, Test Acc: 90.64 %\n",
      "(53/60) epoch end, loss: 0.003751, Test Acc: 90.63 %\n",
      "(54/60) epoch end, loss: 0.003751, Test Acc: 90.67 %\n",
      "(55/60) epoch end, loss: 0.003815, Test Acc: 90.22 %\n",
      "(56/60) epoch end, loss: 0.003804, Test Acc: 90.51 %\n",
      "(57/60) epoch end, loss: 0.003766, Test Acc: 90.08 %\n",
      "(58/60) epoch end, loss: 0.003753, Test Acc: 90.41 %\n",
      "(59/60) epoch end, loss: 0.003780, Test Acc: 90.42 %\n",
      "(60/60) epoch end, loss: 0.003785, Test Acc: 90.30 %\n",
      "\n",
      "Sequential recasting is finished\n"
     ]
    }
   ],
   "source": [
    "# define MSE loss\n",
    "MSE = nn.MSELoss()\n",
    "\n",
    "teacher.TestMode()\n",
    "\n",
    "for block_idx in recasting_block_indices:\n",
    "    \n",
    "    ################################################    Recasting process ######################################################\n",
    "    # current block recasting\n",
    "    \n",
    "    config = student.GetBlockConfig(block_idx)\n",
    "    \n",
    "    config[2] = round(config[2] * compression_ratio)    # apply compression ratio\n",
    "    \n",
    "    # Handling corner case: bottleneck block recasting\n",
    "    if len(config) == 5:                         \n",
    "        is_bottleneck = True\n",
    "        mid_feature = config[4]\n",
    "        # We reduce the output dimension of bottleneck block.\n",
    "        # output dimension of new block is the same with output dimension of 3x3 conv in bottleneck block\n",
    "        config[4] = round(mid_feature * compression_ratio)\n",
    "    else :\n",
    "        is_bottleneck = False\n",
    "        \n",
    "    new_block = model_gen.GenNewBlock([target_block_type, config])\n",
    "    source_block_type = config[0]\n",
    "    \n",
    "    student.Recasting(block_idx, new_block)\n",
    "    \n",
    "    \n",
    "    # next block recasting\n",
    "    \n",
    "    config = student.GetBlockConfig(block_idx + 1)\n",
    "    \n",
    "    config[1] = round(config[1] * compression_ratio)    # apply compression ratio\n",
    "    \n",
    "    # Handling corner case: bottleneck block recasting\n",
    "    if is_bottleneck == True:                         \n",
    "        # Change next input dim to output dim of target block\n",
    "        config[1] = round(mid_feature * compression_ratio)\n",
    "    \n",
    "    new_block = model_gen.GenNewBlock([config[0], config])\n",
    "    student.Recasting(block_idx + 1, new_block)\n",
    "    \n",
    "    ################################################    Recasting process end ##################################################\n",
    "    \n",
    "    \n",
    "    student.Gpu()\n",
    "    \n",
    "    params = student.GetCurrParams(block_idx)\n",
    "    \n",
    "    optimizer = optim.Adam(params, lr = lr_recasting)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size = scheduler_step_size)\n",
    "    \n",
    "    print('\\nBlock %d recasting is done (%s -> %s).' %(block_idx, source_block_type, target_block_type))\n",
    "    print('Training start\\n')\n",
    "    for epoch in range(num_epoch_recasting):  # loop over the dataset multiple times\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        scheduler.step()\n",
    "        \n",
    "        student.TrainMode()\n",
    "            \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            corrects = teacher(inputs, next_block= block_idx + 1)\n",
    "            outputs = student(inputs, next_block = block_idx + 1)\n",
    "\n",
    "            targets = Variable(corrects.data.clone())\n",
    "            \n",
    "            loss = MSE(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss = (running_loss * i + loss.cpu().data.numpy()) / (i+1)\n",
    "\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        student.TestMode()\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = student(Variable(images.cuda()))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.cuda()).sum()\n",
    "        \n",
    "        test_acc = 100 * correct / total\n",
    "        \n",
    "\n",
    "        print('(%d/%d) epoch end, loss: %3.6f, Test Acc: %4.2f %%' %(epoch + 1, num_epoch_recasting, running_loss, test_acc))\n",
    "    \n",
    "    \n",
    "print('\\nSequential recasting is finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning (KD + Cross-entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning start\n",
      "\n",
      "(1/100) epoch end, loss: 2.009247, Test Acc: 87.44 %\n",
      "(2/100) epoch end, loss: 1.749584, Test Acc: 89.63 %\n",
      "(3/100) epoch end, loss: 1.414411, Test Acc: 90.03 %\n",
      "(4/100) epoch end, loss: 1.276406, Test Acc: 90.19 %\n",
      "(5/100) epoch end, loss: 1.258382, Test Acc: 90.25 %\n",
      "(6/100) epoch end, loss: 1.221164, Test Acc: 90.01 %\n",
      "(7/100) epoch end, loss: 1.232249, Test Acc: 90.22 %\n",
      "(8/100) epoch end, loss: 1.195657, Test Acc: 90.22 %\n",
      "(9/100) epoch end, loss: 1.379241, Test Acc: 90.67 %\n",
      "(10/100) epoch end, loss: 1.173740, Test Acc: 90.32 %\n",
      "(11/100) epoch end, loss: 1.090369, Test Acc: 90.44 %\n",
      "(12/100) epoch end, loss: 1.121062, Test Acc: 90.18 %\n",
      "(13/100) epoch end, loss: 1.131535, Test Acc: 90.69 %\n",
      "(14/100) epoch end, loss: 1.079643, Test Acc: 89.84 %\n",
      "(15/100) epoch end, loss: 1.074084, Test Acc: 90.17 %\n",
      "(16/100) epoch end, loss: 1.368078, Test Acc: 90.44 %\n",
      "(17/100) epoch end, loss: 1.046281, Test Acc: 90.66 %\n",
      "(18/100) epoch end, loss: 0.993323, Test Acc: 90.71 %\n",
      "(19/100) epoch end, loss: 0.996222, Test Acc: 90.68 %\n",
      "(20/100) epoch end, loss: 0.968832, Test Acc: 90.07 %\n",
      "(21/100) epoch end, loss: 0.788458, Test Acc: 91.05 %\n",
      "(22/100) epoch end, loss: 0.672848, Test Acc: 91.13 %\n",
      "(23/100) epoch end, loss: 0.628270, Test Acc: 91.21 %\n",
      "(24/100) epoch end, loss: 0.590943, Test Acc: 91.25 %\n",
      "(25/100) epoch end, loss: 0.595119, Test Acc: 91.32 %\n",
      "(26/100) epoch end, loss: 0.584057, Test Acc: 91.47 %\n",
      "(27/100) epoch end, loss: 0.574870, Test Acc: 91.55 %\n",
      "(28/100) epoch end, loss: 0.554948, Test Acc: 91.40 %\n",
      "(29/100) epoch end, loss: 0.548363, Test Acc: 91.41 %\n",
      "(30/100) epoch end, loss: 0.539935, Test Acc: 91.37 %\n",
      "(31/100) epoch end, loss: 0.542674, Test Acc: 91.46 %\n",
      "(32/100) epoch end, loss: 0.520986, Test Acc: 91.47 %\n",
      "(33/100) epoch end, loss: 0.516585, Test Acc: 91.49 %\n",
      "(34/100) epoch end, loss: 0.517487, Test Acc: 91.46 %\n",
      "(35/100) epoch end, loss: 0.519999, Test Acc: 91.56 %\n",
      "(36/100) epoch end, loss: 0.501977, Test Acc: 91.66 %\n",
      "(37/100) epoch end, loss: 0.499233, Test Acc: 91.72 %\n",
      "(38/100) epoch end, loss: 0.491282, Test Acc: 91.72 %\n",
      "(39/100) epoch end, loss: 0.486589, Test Acc: 91.70 %\n",
      "(40/100) epoch end, loss: 0.482102, Test Acc: 91.76 %\n",
      "(41/100) epoch end, loss: 0.487172, Test Acc: 91.70 %\n",
      "(42/100) epoch end, loss: 0.462642, Test Acc: 91.77 %\n",
      "(43/100) epoch end, loss: 0.457959, Test Acc: 91.65 %\n",
      "(44/100) epoch end, loss: 0.455819, Test Acc: 91.70 %\n",
      "(45/100) epoch end, loss: 0.443348, Test Acc: 91.73 %\n",
      "(46/100) epoch end, loss: 0.446144, Test Acc: 91.67 %\n",
      "(47/100) epoch end, loss: 0.469222, Test Acc: 91.77 %\n",
      "(48/100) epoch end, loss: 0.448386, Test Acc: 91.63 %\n",
      "(49/100) epoch end, loss: 0.451072, Test Acc: 91.71 %\n",
      "(50/100) epoch end, loss: 0.454506, Test Acc: 91.76 %\n",
      "(51/100) epoch end, loss: 0.455069, Test Acc: 91.71 %\n",
      "(52/100) epoch end, loss: 0.451658, Test Acc: 91.74 %\n",
      "(53/100) epoch end, loss: 0.448785, Test Acc: 91.80 %\n",
      "(54/100) epoch end, loss: 0.443665, Test Acc: 91.80 %\n",
      "(55/100) epoch end, loss: 0.439168, Test Acc: 91.71 %\n",
      "(56/100) epoch end, loss: 0.458846, Test Acc: 91.66 %\n",
      "(57/100) epoch end, loss: 0.439721, Test Acc: 91.75 %\n",
      "(58/100) epoch end, loss: 0.442297, Test Acc: 91.78 %\n",
      "(59/100) epoch end, loss: 0.449869, Test Acc: 91.78 %\n",
      "(60/100) epoch end, loss: 0.454757, Test Acc: 91.73 %\n",
      "(61/100) epoch end, loss: 0.437364, Test Acc: 91.68 %\n",
      "(62/100) epoch end, loss: 0.429029, Test Acc: 91.71 %\n",
      "(63/100) epoch end, loss: 0.460201, Test Acc: 91.82 %\n",
      "(64/100) epoch end, loss: 0.443214, Test Acc: 91.85 %\n",
      "(65/100) epoch end, loss: 0.438634, Test Acc: 91.68 %\n",
      "(66/100) epoch end, loss: 0.444962, Test Acc: 91.80 %\n",
      "(67/100) epoch end, loss: 0.442111, Test Acc: 91.80 %\n",
      "(68/100) epoch end, loss: 0.444395, Test Acc: 91.74 %\n",
      "(69/100) epoch end, loss: 0.456865, Test Acc: 91.75 %\n",
      "(70/100) epoch end, loss: 0.446415, Test Acc: 91.73 %\n",
      "(71/100) epoch end, loss: 0.448260, Test Acc: 91.79 %\n",
      "(72/100) epoch end, loss: 0.441674, Test Acc: 91.83 %\n",
      "(73/100) epoch end, loss: 0.453470, Test Acc: 91.67 %\n",
      "(74/100) epoch end, loss: 0.433235, Test Acc: 91.76 %\n",
      "(75/100) epoch end, loss: 0.447055, Test Acc: 91.75 %\n",
      "(76/100) epoch end, loss: 0.443704, Test Acc: 91.74 %\n",
      "(77/100) epoch end, loss: 0.455195, Test Acc: 91.82 %\n",
      "(78/100) epoch end, loss: 0.436425, Test Acc: 91.86 %\n",
      "(79/100) epoch end, loss: 0.455801, Test Acc: 91.81 %\n",
      "(80/100) epoch end, loss: 0.437447, Test Acc: 91.80 %\n",
      "(81/100) epoch end, loss: 0.448034, Test Acc: 91.78 %\n",
      "(82/100) epoch end, loss: 0.439645, Test Acc: 91.83 %\n",
      "(83/100) epoch end, loss: 0.437155, Test Acc: 91.76 %\n",
      "(84/100) epoch end, loss: 0.441170, Test Acc: 91.79 %\n",
      "(85/100) epoch end, loss: 0.439689, Test Acc: 91.82 %\n",
      "(86/100) epoch end, loss: 0.442162, Test Acc: 91.73 %\n",
      "(87/100) epoch end, loss: 0.449552, Test Acc: 91.67 %\n",
      "(88/100) epoch end, loss: 0.446141, Test Acc: 91.82 %\n",
      "(89/100) epoch end, loss: 0.441577, Test Acc: 91.74 %\n",
      "(90/100) epoch end, loss: 0.446391, Test Acc: 91.76 %\n",
      "(91/100) epoch end, loss: 0.446015, Test Acc: 91.79 %\n",
      "(92/100) epoch end, loss: 0.446009, Test Acc: 91.74 %\n",
      "(93/100) epoch end, loss: 0.450781, Test Acc: 91.83 %\n",
      "(94/100) epoch end, loss: 0.435300, Test Acc: 91.78 %\n",
      "(95/100) epoch end, loss: 0.434456, Test Acc: 91.77 %\n",
      "(96/100) epoch end, loss: 0.444513, Test Acc: 91.79 %\n",
      "(97/100) epoch end, loss: 0.455655, Test Acc: 91.78 %\n",
      "(98/100) epoch end, loss: 0.447010, Test Acc: 91.80 %\n",
      "(99/100) epoch end, loss: 0.429340, Test Acc: 91.76 %\n",
      "(100/100) epoch end, loss: 0.442229, Test Acc: 91.75 %\n",
      "\n",
      "Fine tuning is finished\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# define loss functions\n",
    "MSE = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# pruning ratio for every layer    \n",
    "optimizer = optim.Adam(student.GetTotalParams(), lr = lr_fine_tune)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size = scheduler_step_size)\n",
    "teacher.TestMode()\n",
    "student.Gpu()\n",
    "\n",
    "print('Fine tuning start\\n')\n",
    "\n",
    "for epoch in range(num_epoch_fine_tune):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    student.TrainMode()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        corrects = teacher(inputs)\n",
    "        outputs = student(inputs)\n",
    "\n",
    "        targets = Variable(corrects.data.clone())\n",
    "        loss_KD = MSE(outputs, targets)\n",
    "        loss_CE = criterion(outputs, labels)\n",
    "        \n",
    "        loss = loss_KD + loss_CE\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = (running_loss * i + loss.cpu().data.numpy()) / (i+1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    student.TestMode()\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = student(Variable(images.cuda()))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "    print('(%d/%d) epoch end, loss: %3.6f, Test Acc: %4.2f %%' %(epoch + 1, num_epoch_fine_tune, running_loss, 100 * correct / total))\n",
    "    \n",
    "print('\\nFine tuning is finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Conv2d(3, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " [Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False),\n",
       " [Conv2d(26, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " [Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False),\n",
       " [Conv2d(51, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " [Conv2d(102, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " [Conv2d(102, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False),\n",
       " [Conv2d(102, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " [Conv2d(205, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " [Conv2d(205, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False),\n",
       " [Conv2d(205, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " [Conv2d(205, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " [Conv2d(205, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'ConvBlock'],\n",
       " MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False),\n",
       " 'Flatten',\n",
       " [Linear(in_features=205, out_features=512, bias=True),\n",
       "  BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  'FCBlock'],\n",
       " [Linear(in_features=512, out_features=10, bias=True), 'FCBlock']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.PrintBlocksDetail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
