{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "from model_generator import ModelGenerator\n",
    "from net import Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epoch  = 200\n",
    "\n",
    "lr = 0.1\n",
    "gamma = 0.2             # learning rate decay\n",
    "weight_decay = 0.0005\n",
    "\n",
    "## for SGD\n",
    "opt_momentum = 0.9\n",
    "opt_nesterov = True\n",
    "\n",
    "dropout_on = False\n",
    "batchnorm_on = True \n",
    "\n",
    "scheduler_step_size = [60, 120, 160]\n",
    "\n",
    "pretrained_model       = './cifar100_wrn_28_10_pretrained.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomCrop(32, 4),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WideResNet-28-10 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen = ModelGenerator(dropout = dropout_on, batchnorm = batchnorm_on)\n",
    "\n",
    "model_gen.CifarWrnConfig(k = 10, num_layers = 28, cifar = 100)\n",
    "model = model_gen.GetCifarWrn()\n",
    "\n",
    "net = Net(model)\n",
    "\n",
    "net.Gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.GetTotalParams(), lr=lr, weight_decay=weight_decay, momentum=opt_momentum, nesterov=opt_nesterov )\n",
    "\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones = scheduler_step_size, gamma = gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch end, loss: 3.961047, Test Acc: 14.96 %\n",
      "2 epoch end, loss: 3.094576, Test Acc: 23.22 %\n",
      "3 epoch end, loss: 2.447427, Test Acc: 36.80 %\n",
      "4 epoch end, loss: 2.031867, Test Acc: 43.53 %\n",
      "5 epoch end, loss: 1.778436, Test Acc: 45.29 %\n",
      "6 epoch end, loss: 1.620624, Test Acc: 48.12 %\n",
      "7 epoch end, loss: 1.499361, Test Acc: 47.26 %\n",
      "8 epoch end, loss: 1.410976, Test Acc: 51.99 %\n",
      "9 epoch end, loss: 1.334886, Test Acc: 52.16 %\n",
      "10 epoch end, loss: 1.279441, Test Acc: 49.65 %\n",
      "11 epoch end, loss: 1.228564, Test Acc: 53.72 %\n",
      "12 epoch end, loss: 1.189186, Test Acc: 54.58 %\n",
      "13 epoch end, loss: 1.150391, Test Acc: 53.02 %\n",
      "14 epoch end, loss: 1.118233, Test Acc: 53.97 %\n",
      "15 epoch end, loss: 1.099350, Test Acc: 58.02 %\n",
      "16 epoch end, loss: 1.070504, Test Acc: 56.66 %\n",
      "17 epoch end, loss: 1.045134, Test Acc: 54.01 %\n",
      "18 epoch end, loss: 1.025262, Test Acc: 57.26 %\n",
      "19 epoch end, loss: 1.014552, Test Acc: 55.36 %\n",
      "20 epoch end, loss: 0.997343, Test Acc: 56.56 %\n",
      "21 epoch end, loss: 0.979964, Test Acc: 59.24 %\n",
      "22 epoch end, loss: 0.968872, Test Acc: 60.49 %\n",
      "23 epoch end, loss: 0.958732, Test Acc: 59.58 %\n",
      "24 epoch end, loss: 0.938508, Test Acc: 58.59 %\n",
      "25 epoch end, loss: 0.938978, Test Acc: 58.58 %\n",
      "26 epoch end, loss: 0.930669, Test Acc: 57.86 %\n",
      "27 epoch end, loss: 0.917821, Test Acc: 59.58 %\n",
      "28 epoch end, loss: 0.902908, Test Acc: 57.22 %\n",
      "29 epoch end, loss: 0.895419, Test Acc: 60.74 %\n",
      "30 epoch end, loss: 0.893789, Test Acc: 60.13 %\n",
      "31 epoch end, loss: 0.885266, Test Acc: 62.30 %\n",
      "32 epoch end, loss: 0.873980, Test Acc: 58.65 %\n",
      "33 epoch end, loss: 0.866973, Test Acc: 58.82 %\n",
      "34 epoch end, loss: 0.856136, Test Acc: 59.73 %\n",
      "35 epoch end, loss: 0.855119, Test Acc: 60.10 %\n",
      "36 epoch end, loss: 0.855076, Test Acc: 58.86 %\n",
      "37 epoch end, loss: 0.850256, Test Acc: 60.29 %\n",
      "38 epoch end, loss: 0.840152, Test Acc: 60.26 %\n",
      "39 epoch end, loss: 0.838777, Test Acc: 62.22 %\n",
      "40 epoch end, loss: 0.834433, Test Acc: 59.72 %\n",
      "41 epoch end, loss: 0.820676, Test Acc: 62.77 %\n",
      "42 epoch end, loss: 0.830775, Test Acc: 58.14 %\n",
      "43 epoch end, loss: 0.824521, Test Acc: 62.44 %\n",
      "44 epoch end, loss: 0.809238, Test Acc: 59.42 %\n",
      "45 epoch end, loss: 0.810501, Test Acc: 59.25 %\n",
      "46 epoch end, loss: 0.818550, Test Acc: 57.55 %\n",
      "47 epoch end, loss: 0.801728, Test Acc: 57.57 %\n",
      "48 epoch end, loss: 0.798340, Test Acc: 61.01 %\n",
      "49 epoch end, loss: 0.803338, Test Acc: 58.73 %\n",
      "50 epoch end, loss: 0.793674, Test Acc: 61.42 %\n",
      "51 epoch end, loss: 0.788572, Test Acc: 62.27 %\n",
      "52 epoch end, loss: 0.788467, Test Acc: 62.82 %\n",
      "53 epoch end, loss: 0.788123, Test Acc: 59.22 %\n",
      "54 epoch end, loss: 0.787160, Test Acc: 60.05 %\n",
      "55 epoch end, loss: 0.780386, Test Acc: 59.36 %\n",
      "56 epoch end, loss: 0.773534, Test Acc: 61.48 %\n",
      "57 epoch end, loss: 0.786996, Test Acc: 59.44 %\n",
      "58 epoch end, loss: 0.786235, Test Acc: 62.64 %\n",
      "59 epoch end, loss: 0.766545, Test Acc: 59.75 %\n",
      "60 epoch end, loss: 0.764411, Test Acc: 61.60 %\n",
      "61 epoch end, loss: 0.333480, Test Acc: 77.27 %\n",
      "62 epoch end, loss: 0.202544, Test Acc: 77.15 %\n",
      "63 epoch end, loss: 0.148216, Test Acc: 77.51 %\n",
      "64 epoch end, loss: 0.114340, Test Acc: 77.48 %\n",
      "65 epoch end, loss: 0.097443, Test Acc: 77.38 %\n",
      "66 epoch end, loss: 0.079399, Test Acc: 77.09 %\n",
      "67 epoch end, loss: 0.074419, Test Acc: 76.99 %\n",
      "68 epoch end, loss: 0.072817, Test Acc: 76.80 %\n",
      "69 epoch end, loss: 0.070338, Test Acc: 76.52 %\n",
      "70 epoch end, loss: 0.071934, Test Acc: 75.59 %\n",
      "71 epoch end, loss: 0.077924, Test Acc: 76.00 %\n",
      "72 epoch end, loss: 0.083216, Test Acc: 75.03 %\n",
      "73 epoch end, loss: 0.104162, Test Acc: 73.69 %\n",
      "74 epoch end, loss: 0.115844, Test Acc: 72.31 %\n",
      "75 epoch end, loss: 0.130553, Test Acc: 73.43 %\n",
      "76 epoch end, loss: 0.146950, Test Acc: 72.23 %\n",
      "77 epoch end, loss: 0.147036, Test Acc: 71.66 %\n",
      "78 epoch end, loss: 0.166104, Test Acc: 71.95 %\n",
      "79 epoch end, loss: 0.166076, Test Acc: 72.44 %\n",
      "80 epoch end, loss: 0.164162, Test Acc: 72.68 %\n",
      "81 epoch end, loss: 0.158561, Test Acc: 69.60 %\n",
      "82 epoch end, loss: 0.157099, Test Acc: 70.97 %\n",
      "83 epoch end, loss: 0.147827, Test Acc: 71.74 %\n",
      "84 epoch end, loss: 0.145170, Test Acc: 71.52 %\n",
      "85 epoch end, loss: 0.157478, Test Acc: 71.14 %\n",
      "86 epoch end, loss: 0.148849, Test Acc: 72.20 %\n",
      "87 epoch end, loss: 0.155892, Test Acc: 72.05 %\n",
      "88 epoch end, loss: 0.150391, Test Acc: 70.90 %\n",
      "89 epoch end, loss: 0.151632, Test Acc: 71.54 %\n",
      "90 epoch end, loss: 0.143499, Test Acc: 69.88 %\n",
      "91 epoch end, loss: 0.134100, Test Acc: 71.27 %\n",
      "92 epoch end, loss: 0.153424, Test Acc: 70.98 %\n",
      "93 epoch end, loss: 0.147707, Test Acc: 70.53 %\n",
      "94 epoch end, loss: 0.163959, Test Acc: 72.13 %\n",
      "95 epoch end, loss: 0.138602, Test Acc: 69.42 %\n",
      "96 epoch end, loss: 0.141824, Test Acc: 70.52 %\n",
      "97 epoch end, loss: 0.136405, Test Acc: 71.00 %\n",
      "98 epoch end, loss: 0.138778, Test Acc: 70.52 %\n",
      "99 epoch end, loss: 0.150677, Test Acc: 71.22 %\n",
      "100 epoch end, loss: 0.134268, Test Acc: 70.73 %\n",
      "101 epoch end, loss: 0.133775, Test Acc: 71.80 %\n",
      "102 epoch end, loss: 0.131960, Test Acc: 69.71 %\n",
      "103 epoch end, loss: 0.142288, Test Acc: 70.33 %\n",
      "104 epoch end, loss: 0.140764, Test Acc: 71.14 %\n",
      "105 epoch end, loss: 0.140706, Test Acc: 71.00 %\n",
      "106 epoch end, loss: 0.135898, Test Acc: 69.61 %\n",
      "107 epoch end, loss: 0.132336, Test Acc: 71.43 %\n",
      "108 epoch end, loss: 0.129693, Test Acc: 71.21 %\n",
      "109 epoch end, loss: 0.128902, Test Acc: 70.93 %\n",
      "110 epoch end, loss: 0.131115, Test Acc: 71.41 %\n",
      "111 epoch end, loss: 0.130034, Test Acc: 71.46 %\n",
      "112 epoch end, loss: 0.133584, Test Acc: 71.72 %\n",
      "113 epoch end, loss: 0.130584, Test Acc: 70.59 %\n",
      "114 epoch end, loss: 0.139241, Test Acc: 72.25 %\n",
      "115 epoch end, loss: 0.135758, Test Acc: 70.23 %\n",
      "116 epoch end, loss: 0.137536, Test Acc: 68.99 %\n",
      "117 epoch end, loss: 0.140032, Test Acc: 70.38 %\n",
      "118 epoch end, loss: 0.129971, Test Acc: 71.54 %\n",
      "119 epoch end, loss: 0.136102, Test Acc: 71.28 %\n",
      "120 epoch end, loss: 0.129617, Test Acc: 70.45 %\n",
      "121 epoch end, loss: 0.038107, Test Acc: 78.56 %\n",
      "122 epoch end, loss: 0.016008, Test Acc: 78.93 %\n",
      "123 epoch end, loss: 0.010611, Test Acc: 79.30 %\n",
      "124 epoch end, loss: 0.008824, Test Acc: 79.27 %\n",
      "125 epoch end, loss: 0.007860, Test Acc: 79.77 %\n",
      "126 epoch end, loss: 0.007502, Test Acc: 79.74 %\n",
      "127 epoch end, loss: 0.006754, Test Acc: 79.63 %\n",
      "128 epoch end, loss: 0.006710, Test Acc: 79.94 %\n",
      "129 epoch end, loss: 0.006591, Test Acc: 79.91 %\n",
      "130 epoch end, loss: 0.006158, Test Acc: 80.01 %\n",
      "131 epoch end, loss: 0.005944, Test Acc: 79.97 %\n",
      "132 epoch end, loss: 0.005975, Test Acc: 79.77 %\n",
      "133 epoch end, loss: 0.005813, Test Acc: 80.04 %\n",
      "134 epoch end, loss: 0.005702, Test Acc: 80.23 %\n",
      "135 epoch end, loss: 0.005570, Test Acc: 80.21 %\n",
      "136 epoch end, loss: 0.005577, Test Acc: 80.24 %\n",
      "137 epoch end, loss: 0.005716, Test Acc: 80.53 %\n",
      "138 epoch end, loss: 0.005862, Test Acc: 80.23 %\n",
      "139 epoch end, loss: 0.005739, Test Acc: 80.40 %\n",
      "140 epoch end, loss: 0.006003, Test Acc: 80.26 %\n",
      "141 epoch end, loss: 0.005945, Test Acc: 80.53 %\n",
      "142 epoch end, loss: 0.005989, Test Acc: 80.38 %\n",
      "143 epoch end, loss: 0.006071, Test Acc: 80.41 %\n",
      "144 epoch end, loss: 0.005961, Test Acc: 80.51 %\n",
      "145 epoch end, loss: 0.006129, Test Acc: 80.66 %\n",
      "146 epoch end, loss: 0.006013, Test Acc: 80.54 %\n",
      "147 epoch end, loss: 0.006428, Test Acc: 80.77 %\n",
      "148 epoch end, loss: 0.006360, Test Acc: 80.50 %\n",
      "149 epoch end, loss: 0.006441, Test Acc: 80.71 %\n",
      "150 epoch end, loss: 0.006301, Test Acc: 80.65 %\n",
      "151 epoch end, loss: 0.006641, Test Acc: 80.72 %\n",
      "152 epoch end, loss: 0.006775, Test Acc: 80.49 %\n",
      "153 epoch end, loss: 0.006860, Test Acc: 80.61 %\n",
      "154 epoch end, loss: 0.006609, Test Acc: 80.74 %\n",
      "155 epoch end, loss: 0.006833, Test Acc: 80.80 %\n",
      "156 epoch end, loss: 0.006856, Test Acc: 80.69 %\n",
      "157 epoch end, loss: 0.006721, Test Acc: 80.77 %\n",
      "158 epoch end, loss: 0.006869, Test Acc: 80.76 %\n",
      "159 epoch end, loss: 0.006883, Test Acc: 80.77 %\n",
      "160 epoch end, loss: 0.006973, Test Acc: 80.63 %\n",
      "161 epoch end, loss: 0.006823, Test Acc: 80.90 %\n",
      "162 epoch end, loss: 0.006861, Test Acc: 80.91 %\n",
      "163 epoch end, loss: 0.006851, Test Acc: 81.05 %\n",
      "164 epoch end, loss: 0.006584, Test Acc: 80.80 %\n",
      "165 epoch end, loss: 0.006725, Test Acc: 81.03 %\n",
      "166 epoch end, loss: 0.006649, Test Acc: 80.94 %\n",
      "167 epoch end, loss: 0.006661, Test Acc: 80.96 %\n",
      "168 epoch end, loss: 0.006773, Test Acc: 81.15 %\n",
      "169 epoch end, loss: 0.006515, Test Acc: 80.93 %\n",
      "170 epoch end, loss: 0.006659, Test Acc: 80.95 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 epoch end, loss: 0.006729, Test Acc: 81.10 %\n",
      "172 epoch end, loss: 0.006683, Test Acc: 80.99 %\n",
      "173 epoch end, loss: 0.006628, Test Acc: 80.94 %\n",
      "174 epoch end, loss: 0.006631, Test Acc: 80.91 %\n",
      "175 epoch end, loss: 0.006581, Test Acc: 80.96 %\n",
      "176 epoch end, loss: 0.006788, Test Acc: 81.02 %\n",
      "177 epoch end, loss: 0.006689, Test Acc: 80.88 %\n",
      "178 epoch end, loss: 0.006654, Test Acc: 81.03 %\n",
      "179 epoch end, loss: 0.006725, Test Acc: 80.89 %\n",
      "180 epoch end, loss: 0.006649, Test Acc: 80.92 %\n",
      "181 epoch end, loss: 0.006732, Test Acc: 81.00 %\n",
      "182 epoch end, loss: 0.006747, Test Acc: 80.85 %\n",
      "183 epoch end, loss: 0.006880, Test Acc: 81.08 %\n",
      "184 epoch end, loss: 0.006706, Test Acc: 81.07 %\n",
      "185 epoch end, loss: 0.006655, Test Acc: 81.04 %\n",
      "186 epoch end, loss: 0.006697, Test Acc: 81.02 %\n",
      "187 epoch end, loss: 0.006967, Test Acc: 81.14 %\n",
      "188 epoch end, loss: 0.006713, Test Acc: 81.22 %\n",
      "189 epoch end, loss: 0.006792, Test Acc: 81.23 %\n",
      "190 epoch end, loss: 0.006696, Test Acc: 81.02 %\n",
      "191 epoch end, loss: 0.006776, Test Acc: 80.94 %\n",
      "192 epoch end, loss: 0.006765, Test Acc: 81.22 %\n",
      "193 epoch end, loss: 0.006888, Test Acc: 81.00 %\n",
      "194 epoch end, loss: 0.006813, Test Acc: 81.17 %\n",
      "195 epoch end, loss: 0.006853, Test Acc: 80.95 %\n",
      "196 epoch end, loss: 0.006815, Test Acc: 81.06 %\n",
      "197 epoch end, loss: 0.006698, Test Acc: 81.07 %\n",
      "198 epoch end, loss: 0.006868, Test Acc: 81.09 %\n",
      "199 epoch end, loss: 0.006784, Test Acc: 80.87 %\n",
      "200 epoch end, loss: 0.006809, Test Acc: 81.19 %\n",
      "\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    net.TrainMode()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        #scheduler.step()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = (running_loss * i + loss.cpu().data.numpy()) / (i+1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.TestMode()\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(Variable(images.cuda()))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "        \n",
    "    print('%d epoch end, loss: %3.6f, Test Acc: %4.2f %%' %(epoch + 1, running_loss, 100 * correct / total))\n",
    "    \n",
    "print('\\nTraining is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 81.19 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "net.TestMode()\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(net.GetStateDict(), pretrained_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
