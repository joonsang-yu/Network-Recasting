{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "from model_generator import ModelGenerator\n",
    "from net import Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dropout_on = True\n",
    "batchnorm_on = True \n",
    "\n",
    "scheduler_step_size = 20\n",
    "\n",
    "## for recasting\n",
    "\n",
    "lr_recasting = 0.001\n",
    "num_epoch_recasting = 60\n",
    "\n",
    "## for fine tune\n",
    "\n",
    "lr_fine_tune = 0.001\n",
    "num_epoch_fine_tune = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen = ModelGenerator(dropout = dropout_on, batchnorm = batchnorm_on)\n",
    "\n",
    "model_gen.CifarDensenetConfig(k = 12, num_layers = 100, cifar = 100)\n",
    "\n",
    "# Recasting block\n",
    "# 0: conv layer, 1, 3, 5: Dense block, 2, 4: Transition block\n",
    "recasting_block_indices = [1, 3, 5]\n",
    "target_block_type = 'ResidualBlock'\n",
    "\n",
    "# Compression rate\n",
    "# the number of filters decreased to [compression_rate]\n",
    "\n",
    "compression_ratio = 1\n",
    "\n",
    "## file path\n",
    "pretrained_model = './cifar100_densenet100_pretrained.pth'\n",
    "compressed_model = './cifar100_densenet100_to_convenet.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomCrop(32, 4),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model (teacher network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.20 %\n"
     ]
    }
   ],
   "source": [
    "model = model_gen.GetCifarDensenet()\n",
    "teacher = Net(model)\n",
    "\n",
    "state = torch.load(pretrained_model)\n",
    "teacher.LoadFromStateDict(state)\n",
    "\n",
    "teacher.Gpu()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "teacher.TestMode()\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = teacher(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define student network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_gen.GetCifarDensenet()\n",
    "student = Net(model)\n",
    "\n",
    "state = torch.load(pretrained_model)\n",
    "student.LoadFromStateDict(state)\n",
    "\n",
    "student.Gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.20 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "student.TestMode()\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = student(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential recasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block 1 recasting is done (DenseBlock -> ResidualBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.016885, Test Acc: 92.28 %\n",
      "(2/60) epoch end, loss: 0.007277, Test Acc: 93.51 %\n",
      "(3/60) epoch end, loss: 0.005723, Test Acc: 94.07 %\n",
      "(4/60) epoch end, loss: 0.004950, Test Acc: 94.23 %\n",
      "(5/60) epoch end, loss: 0.004424, Test Acc: 94.55 %\n",
      "(6/60) epoch end, loss: 0.004003, Test Acc: 94.28 %\n",
      "(7/60) epoch end, loss: 0.003642, Test Acc: 94.59 %\n",
      "(8/60) epoch end, loss: 0.003345, Test Acc: 94.79 %\n",
      "(9/60) epoch end, loss: 0.003108, Test Acc: 94.43 %\n",
      "(10/60) epoch end, loss: 0.002938, Test Acc: 94.79 %\n",
      "(11/60) epoch end, loss: 0.002801, Test Acc: 94.81 %\n",
      "(12/60) epoch end, loss: 0.002684, Test Acc: 94.73 %\n",
      "(13/60) epoch end, loss: 0.002588, Test Acc: 94.80 %\n",
      "(14/60) epoch end, loss: 0.002501, Test Acc: 94.66 %\n",
      "(15/60) epoch end, loss: 0.002417, Test Acc: 94.68 %\n",
      "(16/60) epoch end, loss: 0.002348, Test Acc: 94.91 %\n",
      "(17/60) epoch end, loss: 0.002290, Test Acc: 94.82 %\n",
      "(18/60) epoch end, loss: 0.002234, Test Acc: 94.77 %\n",
      "(19/60) epoch end, loss: 0.002198, Test Acc: 94.74 %\n",
      "(20/60) epoch end, loss: 0.002164, Test Acc: 94.77 %\n",
      "(21/60) epoch end, loss: 0.002009, Test Acc: 94.96 %\n",
      "(22/60) epoch end, loss: 0.002007, Test Acc: 94.96 %\n",
      "(23/60) epoch end, loss: 0.002003, Test Acc: 94.98 %\n",
      "(24/60) epoch end, loss: 0.001999, Test Acc: 94.98 %\n",
      "(25/60) epoch end, loss: 0.001995, Test Acc: 95.00 %\n",
      "(26/60) epoch end, loss: 0.001988, Test Acc: 94.92 %\n",
      "(27/60) epoch end, loss: 0.001988, Test Acc: 94.98 %\n",
      "(28/60) epoch end, loss: 0.001986, Test Acc: 95.02 %\n",
      "(29/60) epoch end, loss: 0.001976, Test Acc: 94.98 %\n",
      "(30/60) epoch end, loss: 0.001972, Test Acc: 94.90 %\n",
      "(31/60) epoch end, loss: 0.001972, Test Acc: 94.89 %\n",
      "(32/60) epoch end, loss: 0.001971, Test Acc: 94.87 %\n",
      "(33/60) epoch end, loss: 0.001965, Test Acc: 94.90 %\n",
      "(34/60) epoch end, loss: 0.001962, Test Acc: 94.95 %\n",
      "(35/60) epoch end, loss: 0.001958, Test Acc: 94.93 %\n",
      "(36/60) epoch end, loss: 0.001956, Test Acc: 94.95 %\n",
      "(37/60) epoch end, loss: 0.001953, Test Acc: 94.93 %\n",
      "(38/60) epoch end, loss: 0.001951, Test Acc: 95.00 %\n",
      "(39/60) epoch end, loss: 0.001951, Test Acc: 94.85 %\n",
      "(40/60) epoch end, loss: 0.001947, Test Acc: 94.90 %\n",
      "(41/60) epoch end, loss: 0.001925, Test Acc: 94.97 %\n",
      "(42/60) epoch end, loss: 0.001921, Test Acc: 94.93 %\n",
      "(43/60) epoch end, loss: 0.001924, Test Acc: 94.92 %\n",
      "(44/60) epoch end, loss: 0.001923, Test Acc: 94.89 %\n",
      "(45/60) epoch end, loss: 0.001920, Test Acc: 94.91 %\n",
      "(46/60) epoch end, loss: 0.001923, Test Acc: 94.93 %\n",
      "(47/60) epoch end, loss: 0.001920, Test Acc: 94.90 %\n",
      "(48/60) epoch end, loss: 0.001919, Test Acc: 94.99 %\n",
      "(49/60) epoch end, loss: 0.001919, Test Acc: 94.94 %\n",
      "(50/60) epoch end, loss: 0.001922, Test Acc: 94.88 %\n",
      "(51/60) epoch end, loss: 0.001922, Test Acc: 94.96 %\n",
      "(52/60) epoch end, loss: 0.001919, Test Acc: 95.00 %\n",
      "(53/60) epoch end, loss: 0.001918, Test Acc: 95.04 %\n",
      "(54/60) epoch end, loss: 0.001922, Test Acc: 94.98 %\n",
      "(55/60) epoch end, loss: 0.001917, Test Acc: 94.95 %\n",
      "(56/60) epoch end, loss: 0.001920, Test Acc: 94.95 %\n",
      "(57/60) epoch end, loss: 0.001919, Test Acc: 95.01 %\n",
      "(58/60) epoch end, loss: 0.001918, Test Acc: 94.98 %\n",
      "(59/60) epoch end, loss: 0.001919, Test Acc: 94.90 %\n",
      "(60/60) epoch end, loss: 0.001917, Test Acc: 94.90 %\n",
      "\n",
      "Block 3 recasting is done (DenseBlock -> ResidualBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 0.014154, Test Acc: 90.73 %\n",
      "(2/60) epoch end, loss: 0.006635, Test Acc: 92.54 %\n",
      "(3/60) epoch end, loss: 0.005681, Test Acc: 92.12 %\n",
      "(4/60) epoch end, loss: 0.005064, Test Acc: 92.72 %\n",
      "(5/60) epoch end, loss: 0.004587, Test Acc: 92.62 %\n",
      "(6/60) epoch end, loss: 0.004220, Test Acc: 92.64 %\n",
      "(7/60) epoch end, loss: 0.003927, Test Acc: 92.21 %\n",
      "(8/60) epoch end, loss: 0.003694, Test Acc: 92.09 %\n",
      "(9/60) epoch end, loss: 0.003496, Test Acc: 93.26 %\n",
      "(10/60) epoch end, loss: 0.003316, Test Acc: 92.90 %\n",
      "(11/60) epoch end, loss: 0.003200, Test Acc: 93.42 %\n",
      "(12/60) epoch end, loss: 0.003101, Test Acc: 92.32 %\n",
      "(13/60) epoch end, loss: 0.003036, Test Acc: 93.87 %\n",
      "(14/60) epoch end, loss: 0.002966, Test Acc: 92.79 %\n",
      "(15/60) epoch end, loss: 0.002913, Test Acc: 93.34 %\n",
      "(16/60) epoch end, loss: 0.002872, Test Acc: 93.06 %\n",
      "(17/60) epoch end, loss: 0.002830, Test Acc: 93.46 %\n",
      "(18/60) epoch end, loss: 0.002804, Test Acc: 93.30 %\n",
      "(19/60) epoch end, loss: 0.002779, Test Acc: 94.06 %\n",
      "(20/60) epoch end, loss: 0.002749, Test Acc: 93.08 %\n",
      "(21/60) epoch end, loss: 0.002544, Test Acc: 94.63 %\n",
      "(22/60) epoch end, loss: 0.002528, Test Acc: 94.58 %\n",
      "(23/60) epoch end, loss: 0.002522, Test Acc: 94.53 %\n",
      "(24/60) epoch end, loss: 0.002520, Test Acc: 94.56 %\n",
      "(25/60) epoch end, loss: 0.002514, Test Acc: 94.58 %\n",
      "(26/60) epoch end, loss: 0.002508, Test Acc: 94.44 %\n",
      "(27/60) epoch end, loss: 0.002506, Test Acc: 94.51 %\n",
      "(28/60) epoch end, loss: 0.002501, Test Acc: 94.73 %\n",
      "(29/60) epoch end, loss: 0.002499, Test Acc: 94.62 %\n",
      "(30/60) epoch end, loss: 0.002496, Test Acc: 94.58 %\n",
      "(31/60) epoch end, loss: 0.002492, Test Acc: 94.61 %\n",
      "(32/60) epoch end, loss: 0.002488, Test Acc: 94.51 %\n",
      "(33/60) epoch end, loss: 0.002484, Test Acc: 94.63 %\n",
      "(34/60) epoch end, loss: 0.002484, Test Acc: 94.57 %\n",
      "(35/60) epoch end, loss: 0.002481, Test Acc: 94.64 %\n",
      "(36/60) epoch end, loss: 0.002480, Test Acc: 94.62 %\n",
      "(37/60) epoch end, loss: 0.002474, Test Acc: 94.55 %\n",
      "(38/60) epoch end, loss: 0.002474, Test Acc: 94.60 %\n",
      "(39/60) epoch end, loss: 0.002469, Test Acc: 94.70 %\n",
      "(40/60) epoch end, loss: 0.002470, Test Acc: 94.51 %\n",
      "(41/60) epoch end, loss: 0.002440, Test Acc: 94.71 %\n",
      "(42/60) epoch end, loss: 0.002441, Test Acc: 94.68 %\n",
      "(43/60) epoch end, loss: 0.002440, Test Acc: 94.68 %\n",
      "(44/60) epoch end, loss: 0.002440, Test Acc: 94.69 %\n",
      "(45/60) epoch end, loss: 0.002437, Test Acc: 94.65 %\n",
      "(46/60) epoch end, loss: 0.002439, Test Acc: 94.67 %\n",
      "(47/60) epoch end, loss: 0.002437, Test Acc: 94.62 %\n",
      "(48/60) epoch end, loss: 0.002438, Test Acc: 94.66 %\n",
      "(49/60) epoch end, loss: 0.002440, Test Acc: 94.67 %\n",
      "(50/60) epoch end, loss: 0.002438, Test Acc: 94.65 %\n",
      "(51/60) epoch end, loss: 0.002436, Test Acc: 94.69 %\n",
      "(52/60) epoch end, loss: 0.002438, Test Acc: 94.66 %\n",
      "(53/60) epoch end, loss: 0.002436, Test Acc: 94.67 %\n",
      "(54/60) epoch end, loss: 0.002436, Test Acc: 94.71 %\n",
      "(55/60) epoch end, loss: 0.002437, Test Acc: 94.64 %\n",
      "(56/60) epoch end, loss: 0.002436, Test Acc: 94.66 %\n",
      "(57/60) epoch end, loss: 0.002433, Test Acc: 94.58 %\n",
      "(58/60) epoch end, loss: 0.002434, Test Acc: 94.62 %\n",
      "(59/60) epoch end, loss: 0.002434, Test Acc: 94.62 %\n",
      "(60/60) epoch end, loss: 0.002431, Test Acc: 94.69 %\n",
      "\n",
      "Block 5 recasting is done (DenseBlock -> ResidualBlock).\n",
      "Training start\n",
      "\n",
      "(1/60) epoch end, loss: 7.949782, Test Acc: 81.54 %\n",
      "(2/60) epoch end, loss: 4.837197, Test Acc: 87.03 %\n",
      "(3/60) epoch end, loss: 4.073712, Test Acc: 87.58 %\n",
      "(4/60) epoch end, loss: 3.642569, Test Acc: 86.69 %\n",
      "(5/60) epoch end, loss: 3.321792, Test Acc: 87.83 %\n",
      "(6/60) epoch end, loss: 3.105603, Test Acc: 85.06 %\n",
      "(7/60) epoch end, loss: 2.914711, Test Acc: 87.12 %\n",
      "(8/60) epoch end, loss: 2.764428, Test Acc: 88.63 %\n",
      "(9/60) epoch end, loss: 2.626958, Test Acc: 89.76 %\n",
      "(10/60) epoch end, loss: 2.525134, Test Acc: 92.01 %\n",
      "(11/60) epoch end, loss: 2.402258, Test Acc: 92.61 %\n",
      "(12/60) epoch end, loss: 2.319635, Test Acc: 91.53 %\n",
      "(13/60) epoch end, loss: 2.240106, Test Acc: 90.04 %\n",
      "(14/60) epoch end, loss: 2.175922, Test Acc: 91.06 %\n",
      "(15/60) epoch end, loss: 2.093081, Test Acc: 89.27 %\n",
      "(16/60) epoch end, loss: 2.040605, Test Acc: 92.86 %\n",
      "(17/60) epoch end, loss: 1.966966, Test Acc: 92.63 %\n",
      "(18/60) epoch end, loss: 1.917098, Test Acc: 90.26 %\n",
      "(19/60) epoch end, loss: 1.879902, Test Acc: 91.81 %\n",
      "(20/60) epoch end, loss: 1.839676, Test Acc: 91.91 %\n",
      "(21/60) epoch end, loss: 1.423557, Test Acc: 94.56 %\n",
      "(22/60) epoch end, loss: 1.333354, Test Acc: 94.77 %\n",
      "(23/60) epoch end, loss: 1.300809, Test Acc: 94.67 %\n",
      "(24/60) epoch end, loss: 1.281664, Test Acc: 94.76 %\n",
      "(25/60) epoch end, loss: 1.258531, Test Acc: 94.65 %\n",
      "(26/60) epoch end, loss: 1.243161, Test Acc: 94.63 %\n",
      "(27/60) epoch end, loss: 1.233136, Test Acc: 94.54 %\n",
      "(28/60) epoch end, loss: 1.215875, Test Acc: 94.81 %\n",
      "(29/60) epoch end, loss: 1.205418, Test Acc: 94.78 %\n",
      "(30/60) epoch end, loss: 1.194843, Test Acc: 94.80 %\n",
      "(31/60) epoch end, loss: 1.191562, Test Acc: 94.84 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32/60) epoch end, loss: 1.181832, Test Acc: 94.82 %\n",
      "(33/60) epoch end, loss: 1.174728, Test Acc: 94.77 %\n",
      "(34/60) epoch end, loss: 1.160874, Test Acc: 94.72 %\n",
      "(35/60) epoch end, loss: 1.154601, Test Acc: 94.74 %\n",
      "(36/60) epoch end, loss: 1.144249, Test Acc: 94.81 %\n",
      "(37/60) epoch end, loss: 1.140575, Test Acc: 94.89 %\n",
      "(38/60) epoch end, loss: 1.128954, Test Acc: 94.89 %\n",
      "(39/60) epoch end, loss: 1.122969, Test Acc: 94.89 %\n",
      "(40/60) epoch end, loss: 1.115632, Test Acc: 94.87 %\n",
      "(41/60) epoch end, loss: 1.079099, Test Acc: 94.91 %\n",
      "(42/60) epoch end, loss: 1.065370, Test Acc: 94.97 %\n",
      "(43/60) epoch end, loss: 1.070482, Test Acc: 94.83 %\n",
      "(44/60) epoch end, loss: 1.065442, Test Acc: 94.86 %\n",
      "(45/60) epoch end, loss: 1.069893, Test Acc: 94.98 %\n",
      "(46/60) epoch end, loss: 1.066901, Test Acc: 94.90 %\n",
      "(47/60) epoch end, loss: 1.066294, Test Acc: 94.93 %\n",
      "(48/60) epoch end, loss: 1.067490, Test Acc: 94.98 %\n",
      "(49/60) epoch end, loss: 1.057463, Test Acc: 94.85 %\n",
      "(50/60) epoch end, loss: 1.061201, Test Acc: 94.89 %\n",
      "(51/60) epoch end, loss: 1.063048, Test Acc: 94.97 %\n",
      "(52/60) epoch end, loss: 1.058730, Test Acc: 94.83 %\n",
      "(53/60) epoch end, loss: 1.055840, Test Acc: 94.87 %\n",
      "(54/60) epoch end, loss: 1.060875, Test Acc: 94.88 %\n",
      "(55/60) epoch end, loss: 1.053160, Test Acc: 94.89 %\n",
      "(56/60) epoch end, loss: 1.055092, Test Acc: 94.94 %\n",
      "(57/60) epoch end, loss: 1.051607, Test Acc: 94.96 %\n",
      "(58/60) epoch end, loss: 1.051486, Test Acc: 94.88 %\n",
      "(59/60) epoch end, loss: 1.050914, Test Acc: 94.93 %\n",
      "(60/60) epoch end, loss: 1.046478, Test Acc: 94.86 %\n",
      "\n",
      "Sequential recasting is finished\n"
     ]
    }
   ],
   "source": [
    "# define MSE loss\n",
    "MSE = nn.MSELoss()\n",
    "\n",
    "teacher.TestMode()\n",
    "\n",
    "for block_idx in recasting_block_indices:\n",
    "    \n",
    "    ################################################    Recasting process ######################################################\n",
    "    # current block recasting\n",
    "    \n",
    "    config = student.GetBlockConfig(block_idx)\n",
    "    \n",
    "    config[2] = round(config[2] * compression_ratio)    # apply compression ratio\n",
    "    \n",
    "    # Handling corner case: bottleneck block recasting\n",
    "    if len(config) == 5:                         \n",
    "        is_bottleneck = True\n",
    "        mid_feature = config[4]\n",
    "        # We reduce the output dimension of bottleneck block.\n",
    "        # output dimension of new block is the same with output dimension of 3x3 conv in bottleneck block\n",
    "        config[4] = round(mid_feature * compression_ratio)\n",
    "    else :\n",
    "        is_bottleneck = False\n",
    "        \n",
    "    new_block = model_gen.GenNewBlock([target_block_type, config])\n",
    "    source_block_type = config[0]\n",
    "    \n",
    "    student.Recasting(block_idx, new_block)\n",
    "    \n",
    "    \n",
    "    # next block recasting\n",
    "    \n",
    "    config = student.GetBlockConfig(block_idx + 1)\n",
    "    \n",
    "    config[1] = round(config[1] * compression_ratio)    # apply compression ratio\n",
    "    \n",
    "    # Handling corner case: bottleneck block recasting\n",
    "    if is_bottleneck == True:                         \n",
    "        # Change next input dim to output dim of target block\n",
    "        config[1] = round(mid_feature * compression_ratio)\n",
    "    \n",
    "    new_block = model_gen.GenNewBlock([config[0], config])\n",
    "    student.Recasting(block_idx + 1, new_block)\n",
    "    \n",
    "    ################################################    Recasting process end ##################################################\n",
    "    \n",
    "    \n",
    "    student.Gpu()\n",
    "    \n",
    "    params = student.GetCurrParams(block_idx)\n",
    "    \n",
    "    optimizer = optim.Adam(params, lr = lr_recasting)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size = scheduler_step_size)\n",
    "    \n",
    "    print('\\nBlock %d recasting is done (%s -> %s).' %(block_idx, source_block_type, target_block_type))\n",
    "    print('Training start\\n')\n",
    "    for epoch in range(num_epoch_recasting):  # loop over the dataset multiple times\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        scheduler.step()\n",
    "        \n",
    "        student.TrainMode()\n",
    "            \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            corrects = teacher(inputs, next_block= block_idx + 2)\n",
    "            outputs = student(inputs, next_block = block_idx + 2)\n",
    "\n",
    "            targets = Variable(corrects.data.clone())\n",
    "            \n",
    "            loss = MSE(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss = (running_loss * i + loss.cpu().data.numpy()) / (i+1)\n",
    "\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        student.TestMode()\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = student(Variable(images.cuda()))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.cuda()).sum()\n",
    "        \n",
    "        test_acc = 100 * correct / total\n",
    "        \n",
    "\n",
    "        print('(%d/%d) epoch end, loss: %3.6f, Test Acc: %4.2f %%' %(epoch + 1, num_epoch_recasting, running_loss, test_acc))\n",
    "    \n",
    "    \n",
    "print('\\nSequential recasting is finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning (KD + Cross-entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning start\n",
      "\n",
      "(1/100) epoch end, loss: 1.663972, Test Acc: 92.00 %\n",
      "(2/100) epoch end, loss: 1.680449, Test Acc: 92.37 %\n",
      "(3/100) epoch end, loss: 1.642483, Test Acc: 93.03 %\n",
      "(4/100) epoch end, loss: 1.603471, Test Acc: 93.37 %\n",
      "(5/100) epoch end, loss: 1.589487, Test Acc: 89.87 %\n",
      "(6/100) epoch end, loss: 1.569978, Test Acc: 93.04 %\n",
      "(7/100) epoch end, loss: 1.542852, Test Acc: 93.18 %\n",
      "(8/100) epoch end, loss: 1.523194, Test Acc: 93.15 %\n",
      "(9/100) epoch end, loss: 1.511104, Test Acc: 93.60 %\n",
      "(10/100) epoch end, loss: 1.472328, Test Acc: 93.62 %\n",
      "(11/100) epoch end, loss: 1.448380, Test Acc: 93.96 %\n",
      "(12/100) epoch end, loss: 1.446963, Test Acc: 93.81 %\n",
      "(13/100) epoch end, loss: 1.442419, Test Acc: 93.97 %\n",
      "(14/100) epoch end, loss: 1.404044, Test Acc: 92.75 %\n",
      "(15/100) epoch end, loss: 1.395079, Test Acc: 93.67 %\n",
      "(16/100) epoch end, loss: 1.383039, Test Acc: 93.75 %\n",
      "(17/100) epoch end, loss: 1.351895, Test Acc: 93.62 %\n",
      "(18/100) epoch end, loss: 1.344397, Test Acc: 93.30 %\n",
      "(19/100) epoch end, loss: 1.318826, Test Acc: 94.19 %\n",
      "(20/100) epoch end, loss: 1.306906, Test Acc: 93.46 %\n",
      "(21/100) epoch end, loss: 1.054471, Test Acc: 94.86 %\n",
      "(22/100) epoch end, loss: 0.992301, Test Acc: 94.85 %\n",
      "(23/100) epoch end, loss: 0.971208, Test Acc: 94.81 %\n",
      "(24/100) epoch end, loss: 0.951394, Test Acc: 94.76 %\n",
      "(25/100) epoch end, loss: 0.945237, Test Acc: 94.89 %\n",
      "(26/100) epoch end, loss: 0.936531, Test Acc: 94.84 %\n",
      "(27/100) epoch end, loss: 0.927941, Test Acc: 94.88 %\n",
      "(28/100) epoch end, loss: 0.920438, Test Acc: 94.94 %\n",
      "(29/100) epoch end, loss: 0.915201, Test Acc: 94.82 %\n",
      "(30/100) epoch end, loss: 0.907761, Test Acc: 94.85 %\n",
      "(31/100) epoch end, loss: 0.906655, Test Acc: 94.90 %\n",
      "(32/100) epoch end, loss: 0.900313, Test Acc: 94.86 %\n",
      "(33/100) epoch end, loss: 0.891687, Test Acc: 95.00 %\n",
      "(34/100) epoch end, loss: 0.885980, Test Acc: 94.97 %\n",
      "(35/100) epoch end, loss: 0.884245, Test Acc: 94.96 %\n",
      "(36/100) epoch end, loss: 0.876378, Test Acc: 94.91 %\n",
      "(37/100) epoch end, loss: 0.872741, Test Acc: 94.91 %\n",
      "(38/100) epoch end, loss: 0.872536, Test Acc: 94.98 %\n",
      "(39/100) epoch end, loss: 0.871314, Test Acc: 95.08 %\n",
      "(40/100) epoch end, loss: 0.861497, Test Acc: 94.96 %\n",
      "(41/100) epoch end, loss: 0.842755, Test Acc: 94.87 %\n",
      "(42/100) epoch end, loss: 0.843178, Test Acc: 94.95 %\n",
      "(43/100) epoch end, loss: 0.832453, Test Acc: 94.94 %\n",
      "(44/100) epoch end, loss: 0.841943, Test Acc: 95.02 %\n",
      "(45/100) epoch end, loss: 0.834454, Test Acc: 95.03 %\n",
      "(46/100) epoch end, loss: 0.834015, Test Acc: 94.99 %\n",
      "(47/100) epoch end, loss: 0.830836, Test Acc: 94.86 %\n",
      "(48/100) epoch end, loss: 0.834901, Test Acc: 95.01 %\n",
      "(49/100) epoch end, loss: 0.832296, Test Acc: 94.97 %\n",
      "(50/100) epoch end, loss: 0.835460, Test Acc: 94.91 %\n",
      "(51/100) epoch end, loss: 0.830047, Test Acc: 94.88 %\n",
      "(52/100) epoch end, loss: 0.829217, Test Acc: 94.99 %\n",
      "(53/100) epoch end, loss: 0.828860, Test Acc: 94.91 %\n",
      "(54/100) epoch end, loss: 0.826072, Test Acc: 94.96 %\n",
      "(55/100) epoch end, loss: 0.827393, Test Acc: 94.94 %\n",
      "(56/100) epoch end, loss: 0.830225, Test Acc: 94.95 %\n",
      "(57/100) epoch end, loss: 0.827377, Test Acc: 94.99 %\n",
      "(58/100) epoch end, loss: 0.830692, Test Acc: 95.08 %\n",
      "(59/100) epoch end, loss: 0.826200, Test Acc: 94.96 %\n",
      "(60/100) epoch end, loss: 0.826381, Test Acc: 94.98 %\n",
      "(61/100) epoch end, loss: 0.823227, Test Acc: 94.98 %\n",
      "(62/100) epoch end, loss: 0.823093, Test Acc: 94.95 %\n",
      "(63/100) epoch end, loss: 0.824861, Test Acc: 94.99 %\n",
      "(64/100) epoch end, loss: 0.823361, Test Acc: 94.97 %\n",
      "(65/100) epoch end, loss: 0.824548, Test Acc: 95.00 %\n",
      "(66/100) epoch end, loss: 0.825530, Test Acc: 94.97 %\n",
      "(67/100) epoch end, loss: 0.825859, Test Acc: 94.93 %\n",
      "(68/100) epoch end, loss: 0.823884, Test Acc: 94.95 %\n",
      "(69/100) epoch end, loss: 0.824224, Test Acc: 94.94 %\n",
      "(70/100) epoch end, loss: 0.823024, Test Acc: 94.98 %\n",
      "(71/100) epoch end, loss: 0.823181, Test Acc: 95.05 %\n",
      "(72/100) epoch end, loss: 0.825234, Test Acc: 94.95 %\n",
      "(73/100) epoch end, loss: 0.821067, Test Acc: 95.12 %\n",
      "(74/100) epoch end, loss: 0.823255, Test Acc: 95.00 %\n",
      "(75/100) epoch end, loss: 0.822943, Test Acc: 95.03 %\n",
      "(76/100) epoch end, loss: 0.824416, Test Acc: 94.96 %\n",
      "(77/100) epoch end, loss: 0.823972, Test Acc: 94.97 %\n",
      "(78/100) epoch end, loss: 0.822028, Test Acc: 95.01 %\n",
      "(79/100) epoch end, loss: 0.819425, Test Acc: 95.02 %\n",
      "(80/100) epoch end, loss: 0.822437, Test Acc: 94.94 %\n",
      "(81/100) epoch end, loss: 0.823131, Test Acc: 94.93 %\n",
      "(82/100) epoch end, loss: 0.821786, Test Acc: 95.09 %\n",
      "(83/100) epoch end, loss: 0.823159, Test Acc: 94.93 %\n",
      "(84/100) epoch end, loss: 0.821994, Test Acc: 95.00 %\n",
      "(85/100) epoch end, loss: 0.824301, Test Acc: 95.00 %\n",
      "(86/100) epoch end, loss: 0.823792, Test Acc: 94.93 %\n",
      "(87/100) epoch end, loss: 0.826782, Test Acc: 95.05 %\n",
      "(88/100) epoch end, loss: 0.822884, Test Acc: 94.92 %\n",
      "(89/100) epoch end, loss: 0.824932, Test Acc: 94.95 %\n",
      "(90/100) epoch end, loss: 0.823845, Test Acc: 94.98 %\n",
      "(91/100) epoch end, loss: 0.821466, Test Acc: 95.04 %\n",
      "(92/100) epoch end, loss: 0.824543, Test Acc: 94.99 %\n",
      "(93/100) epoch end, loss: 0.825716, Test Acc: 94.99 %\n",
      "(94/100) epoch end, loss: 0.823382, Test Acc: 94.99 %\n",
      "(95/100) epoch end, loss: 0.824462, Test Acc: 94.93 %\n",
      "(96/100) epoch end, loss: 0.821392, Test Acc: 94.93 %\n",
      "(97/100) epoch end, loss: 0.818886, Test Acc: 94.90 %\n",
      "(98/100) epoch end, loss: 0.818106, Test Acc: 94.95 %\n",
      "(99/100) epoch end, loss: 0.821730, Test Acc: 95.00 %\n",
      "(100/100) epoch end, loss: 0.822758, Test Acc: 95.03 %\n",
      "\n",
      "Fine tuning is finished\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# define loss functions\n",
    "MSE = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# pruning ratio for every layer    \n",
    "optimizer = optim.Adam(student.GetTotalParams(), lr = lr_fine_tune)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size = scheduler_step_size)\n",
    "teacher.TestMode()\n",
    "student.Gpu()\n",
    "\n",
    "print('Fine tuning start\\n')\n",
    "\n",
    "for epoch in range(num_epoch_fine_tune):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    student.TrainMode()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        corrects = teacher(inputs)\n",
    "        outputs = student(inputs)\n",
    "\n",
    "        targets = Variable(corrects.data.clone())\n",
    "        loss_KD = MSE(outputs, targets)\n",
    "        loss_CE = criterion(outputs, labels)\n",
    "        \n",
    "        loss = loss_KD + loss_CE\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = (running_loss * i + loss.cpu().data.numpy()) / (i+1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    student.TestMode()\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = student(Variable(images.cuda()))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "    print('(%d/%d) epoch end, loss: %3.6f, Test Acc: %4.2f %%' %(epoch + 1, num_epoch_fine_tune, running_loss, 100 * correct / total))\n",
    "    \n",
    "print('\\nFine tuning is finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'ConvBlock'],\n",
       " [Conv2d(24, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True),\n",
       "  [Conv2d(24, 216, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True)],\n",
       "  ReLU(inplace),\n",
       "  'ResidualBlock'],\n",
       " [Conv2d(216, 108, kernel_size=(1, 1), stride=(1, 1)), 'ConvBlock'],\n",
       " AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True),\n",
       " [Conv2d(108, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True),\n",
       "  [Conv2d(108, 300, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True)],\n",
       "  ReLU(inplace),\n",
       "  'ResidualBlock'],\n",
       " [Conv2d(300, 150, kernel_size=(1, 1), stride=(1, 1)), 'ConvBlock'],\n",
       " AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True),\n",
       " [Conv2d(150, 342, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  BatchNorm2d(342, eps=1e-05, momentum=0.1, affine=True),\n",
       "  ReLU(inplace),\n",
       "  Conv2d(342, 342, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  BatchNorm2d(342, eps=1e-05, momentum=0.1, affine=True),\n",
       "  [Conv2d(150, 342, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       "   BatchNorm2d(342, eps=1e-05, momentum=0.1, affine=True)],\n",
       "  ReLU(inplace),\n",
       "  'ResidualBlock'],\n",
       " AvgPool2d(kernel_size=8, stride=8, padding=0, ceil_mode=False, count_include_pad=True),\n",
       " 'Flatten',\n",
       " [Linear(in_features=342, out_features=10, bias=True), 'FCBlock']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.PrintBlocksDetail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
